{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "this file is to find a solution by neural-network (GAN) from data (energy-base)\n",
    "核心思想是energy-base的数据驱动的生成ode试探解-神经网络.\n",
    "Energy-GAN for ode-trial solution\n",
    "对于gan这个模型来说，我们需要的是一个生成器，一个判别器，一个自适应的损失函数\n",
    "1.**第一步我们先构造一个基础的基函数的矩阵**\n",
    "生成器：，他在其中进行采样，构造出一个函数f(x),系数是这个矩阵的列向量的系数。\n",
    "\n",
    "对于判别器来说，f(x)利用在其中进行采样，在initial condition 判断这个函数是否是一个解。这里的判别器是不是二分类的问题，wgan-gp\n",
    "2.**trick：对于这个基函数的矩阵 我门加一点noise，在loss下降不去的地方，说不定能试探出来**\n",
    "这个case，我们就暂定是一个y=f(x)的形式,\n",
    "3.**损失函数：生成器中最后泛函形式的能量，最后矩阵的变化准则：函数的内积**\n",
    "\n",
    "矩阵形式（暂时拍脑袋）\n",
    "（后期是不是可以用f-principle来选择-理论来自：NIPS 2021，\n",
    "或者获取物理的先验知识，z-教师网络一起蒸馏\n",
    "或者转化为含时间的决策问题-强化学习问题？\n",
    "在深入需要加入图神经网络的问题吗？）\n",
    "\\begin{bmatrix}\n",
    " 1_{t_0}& x_{t_0} &\\cdots&\\\\\n",
    " 1_{t_1}& x_{t_1} &\\cdots&\\\\\n",
    " \\vdots & \\vdots  &\\vdots &\\\\\n",
    "\\end{bmatrix}\n",
    "4.矩阵的列是基函数的系数，行是采样点，我们可以通过这个矩阵的秩来控制基函数的个数。\n",
    "**简单一点我们这里trancate列是4列，1000个点，是4*1000**（后期是不是可以随机采样？）\n",
    "总结：像解算子的问题。\n",
    "可优化点：1.Fenchel Conjugate共轭函数 2.互信息估计 \\y_hat\n",
    "～交流完看一下书，p22-23 朗斯基的导数问题\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "##定义可控的生成器网络 ，输入是噪声，生成矩阵的基函数。然后在矩阵中随机采样。输出是【ini_con,t,ydot,y】。 在loss中，我们需要判断这个函数是否是一个解，用生成的“能量”来控制。\n",
    "$$ w-gan的理论：lipschitz条件下的loss=D(real)-D(G(x)) $$\n",
    "$$ 生成器与第一项无关，表示为G_{loss}=-D(G(x))$$\n",
    "$$ 评价器，表示为D_{loss}=D(G(x))-D(real)$$\n",
    "$$为满足lipschitz条件下，我们需要当输入的样本稍微变化，评价器输出的结果也要稍微变化，trick:截断参数[-1e-2,1e-2]，clip-\\虽然有问题$$\n",
    "为什么说是可控的呢？  因为我们的能量（基函数的选取，数值矩阵中列自己的内积）是可控的，\\这对生成器的输出是有影响的,即，我们的生成器的输出是可控的，$$\\可控也可以训练一个neural-network取选择列eg.x^4(\\现在没有写这个功能,目前集中在生成参数\\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4)$$\n",
    "$$\\今天的case，主要集中在loss上，如果选择列中能量很大比如x^3,我们的\\alpha_4 小一点-penalty,\\物理意义，节省跳跃能量，就能生成的很好$$\n",
    "$$G_{loss}=-D(G(x))+\\beta*energy(\\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4)$$\n",
    "\n",
    "eg. 输入的z是噪声，输出4个$$ \\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4 $$\n",
    "\n",
    "对于原来的矩阵：我们的试探函数是 $$\\widetilde{\\phi(t)} =\\alpha_1 \\psi_1(t)+...+\\alpha_4 \\psi_4(t) $$\n",
    "*对于生成器，我们输入的是噪声，输出是\\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4 在矩阵\\Matrix 下的列的系数。经过组合后，生成$$y(t)（其实也可以\\dot{y},这次时间比较紧，暂定y(t)，维度是【100*4】*\n",
    "【ini_condition,t,yprime,\\widetilde{\\phi(t)}】$$\n",
    "\n",
    "\n",
    "*对于判别器，是一个监督任务,$$输出是score，对第4列y(t)进行监督，由于我们有y(t)的真实值，我们需要判断这y resiual=y(t)-\\widetilde{\\phi(t)},\n",
    "输入是【100*4】，【ini_condition,t,yprime,yresiual(t)】,输出是score\n",
    "\n",
    "我们有y(t)的真实值，我们需要判断这个函数是否是一个解，正常来说y_resiual=0,score就越高。$$\n",
    "\n",
    "*后期为了提高效率，是不是可以拉丁超采样或者高斯过程或者随机抽样？ 是不是loss放在判别器好一点？用能量拉开真假样本的差距 ,现在打算energy放在生成器的loss*\n",
    "\n",
    "*使用的时候，我们输入1个随机数，能够生成类似的曲线即成功，然后拿到四个参数和基函数的解析表达式，就是有解*\n",
    "\n",
    "*参数的非线性* eg. $$ y= \\alpha_1 \\psi_1(t)+...+\\alpha_4 *\\alpha_n\\psi_4(t) $$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset,TensorDataset\n",
    "#关掉warning\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 定义数据集类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.data[index], dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T04:44:30.022734Z",
     "start_time": "2023-07-20T04:44:30.017631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T04:44:30.923953Z",
     "start_time": "2023-07-20T04:44:30.916085Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [array([1, 2, 3, 4, 5])]\n",
      " [array([ 1,  4,  9, 16, 25])]\n",
      " [array([  1,   8,  27,  64, 125])]]\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "def create_matrix(): #数值矩阵\n",
    "        # 创建符号变量\n",
    "        x = sp.symbols('x')\n",
    "        # 构建运算矩阵\n",
    "        matrix = sp.Matrix([x**i for i in range(4)])\n",
    "        # 输入 x 的值 100*1的值\n",
    "        matrix_fn=sp.lambdify(x, matrix,'numpy')\n",
    "        # 计算矩阵的值\n",
    "        x_values = np.array([1, 2, 3, 4, 5])  # 创建一个向量\n",
    "        result = matrix_fn(x_values)\n",
    "        # 打印函数的符号表示\n",
    "        f_symbolic = sp.pretty(matrix)\n",
    "        a=result[2][0]\n",
    "        print(result)\n",
    "create_matrix()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T04:44:40.389644Z",
     "start_time": "2023-07-20T04:44:40.387938Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "#把随机数定一下\n",
    "import random\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T04:44:44.937646Z",
     "start_time": "2023-07-20T04:44:44.923032Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 4])\n",
      "tensor([[[ 0.0000,  0.0000,  1.0000,  0.0000],\n",
      "         [ 0.0000,  0.1010,  1.0000,  0.1010],\n",
      "         [ 0.0000,  0.2020,  1.0000,  0.2020],\n",
      "         [ 0.0000,  0.3030,  1.0000,  0.3030],\n",
      "         [ 0.0000,  0.4040,  1.0000,  0.4040],\n",
      "         [ 0.0000,  0.5051,  1.0000,  0.5051],\n",
      "         [ 0.0000,  0.6061,  1.0000,  0.6061],\n",
      "         [ 0.0000,  0.7071,  1.0000,  0.7071],\n",
      "         [ 0.0000,  0.8081,  1.0000,  0.8081],\n",
      "         [ 0.0000,  0.9091,  1.0000,  0.9091],\n",
      "         [ 0.0000,  1.0101,  1.0000,  1.0101],\n",
      "         [ 0.0000,  1.1111,  1.0000,  1.1111],\n",
      "         [ 0.0000,  1.2121,  1.0000,  1.2121],\n",
      "         [ 0.0000,  1.3131,  1.0000,  1.3131],\n",
      "         [ 0.0000,  1.4141,  1.0000,  1.4141],\n",
      "         [ 0.0000,  1.5152,  1.0000,  1.5152],\n",
      "         [ 0.0000,  1.6162,  1.0000,  1.6162],\n",
      "         [ 0.0000,  1.7172,  1.0000,  1.7172],\n",
      "         [ 0.0000,  1.8182,  1.0000,  1.8182],\n",
      "         [ 0.0000,  1.9192,  1.0000,  1.9192],\n",
      "         [ 0.0000,  2.0202,  1.0000,  2.0202],\n",
      "         [ 0.0000,  2.1212,  1.0000,  2.1212],\n",
      "         [ 0.0000,  2.2222,  1.0000,  2.2222],\n",
      "         [ 0.0000,  2.3232,  1.0000,  2.3232],\n",
      "         [ 0.0000,  2.4242,  1.0000,  2.4242],\n",
      "         [ 0.0000,  2.5253,  1.0000,  2.5253],\n",
      "         [ 0.0000,  2.6263,  1.0000,  2.6263],\n",
      "         [ 0.0000,  2.7273,  1.0000,  2.7273],\n",
      "         [ 0.0000,  2.8283,  1.0000,  2.8283],\n",
      "         [ 0.0000,  2.9293,  1.0000,  2.9293],\n",
      "         [ 0.0000,  3.0303,  1.0000,  3.0303],\n",
      "         [ 0.0000,  3.1313,  1.0000,  3.1313],\n",
      "         [ 0.0000,  3.2323,  1.0000,  3.2323],\n",
      "         [ 0.0000,  3.3333,  1.0000,  3.3333],\n",
      "         [ 0.0000,  3.4343,  1.0000,  3.4343],\n",
      "         [ 0.0000,  3.5354,  1.0000,  3.5354],\n",
      "         [ 0.0000,  3.6364,  1.0000,  3.6364],\n",
      "         [ 0.0000,  3.7374,  1.0000,  3.7374],\n",
      "         [ 0.0000,  3.8384,  1.0000,  3.8384],\n",
      "         [ 0.0000,  3.9394,  1.0000,  3.9394],\n",
      "         [ 0.0000,  4.0404,  1.0000,  4.0404],\n",
      "         [ 0.0000,  4.1414,  1.0000,  4.1414],\n",
      "         [ 0.0000,  4.2424,  1.0000,  4.2424],\n",
      "         [ 0.0000,  4.3434,  1.0000,  4.3434],\n",
      "         [ 0.0000,  4.4444,  1.0000,  4.4444],\n",
      "         [ 0.0000,  4.5455,  1.0000,  4.5455],\n",
      "         [ 0.0000,  4.6465,  1.0000,  4.6465],\n",
      "         [ 0.0000,  4.7475,  1.0000,  4.7475],\n",
      "         [ 0.0000,  4.8485,  1.0000,  4.8485],\n",
      "         [ 0.0000,  4.9495,  1.0000,  4.9495],\n",
      "         [ 0.0000,  5.0505,  1.0000,  5.0505],\n",
      "         [ 0.0000,  5.1515,  1.0000,  5.1515],\n",
      "         [ 0.0000,  5.2525,  1.0000,  5.2525],\n",
      "         [ 0.0000,  5.3535,  1.0000,  5.3535],\n",
      "         [ 0.0000,  5.4545,  1.0000,  5.4545],\n",
      "         [ 0.0000,  5.5556,  1.0000,  5.5556],\n",
      "         [ 0.0000,  5.6566,  1.0000,  5.6566],\n",
      "         [ 0.0000,  5.7576,  1.0000,  5.7576],\n",
      "         [ 0.0000,  5.8586,  1.0000,  5.8586],\n",
      "         [ 0.0000,  5.9596,  1.0000,  5.9596],\n",
      "         [ 0.0000,  6.0606,  1.0000,  6.0606],\n",
      "         [ 0.0000,  6.1616,  1.0000,  6.1616],\n",
      "         [ 0.0000,  6.2626,  1.0000,  6.2626],\n",
      "         [ 0.0000,  6.3636,  1.0000,  6.3636],\n",
      "         [ 0.0000,  6.4646,  1.0000,  6.4646],\n",
      "         [ 0.0000,  6.5657,  1.0000,  6.5657],\n",
      "         [ 0.0000,  6.6667,  1.0000,  6.6667],\n",
      "         [ 0.0000,  6.7677,  1.0000,  6.7677],\n",
      "         [ 0.0000,  6.8687,  1.0000,  6.8687],\n",
      "         [ 0.0000,  6.9697,  1.0000,  6.9697],\n",
      "         [ 0.0000,  7.0707,  1.0000,  7.0707],\n",
      "         [ 0.0000,  7.1717,  1.0000,  7.1717],\n",
      "         [ 0.0000,  7.2727,  1.0000,  7.2727],\n",
      "         [ 0.0000,  7.3737,  1.0000,  7.3737],\n",
      "         [ 0.0000,  7.4747,  1.0000,  7.4747],\n",
      "         [ 0.0000,  7.5758,  1.0000,  7.5758],\n",
      "         [ 0.0000,  7.6768,  1.0000,  7.6768],\n",
      "         [ 0.0000,  7.7778,  1.0000,  7.7778],\n",
      "         [ 0.0000,  7.8788,  1.0000,  7.8788],\n",
      "         [ 0.0000,  7.9798,  1.0000,  7.9798],\n",
      "         [ 0.0000,  8.0808,  1.0000,  8.0808],\n",
      "         [ 0.0000,  8.1818,  1.0000,  8.1818],\n",
      "         [ 0.0000,  8.2828,  1.0000,  8.2828],\n",
      "         [ 0.0000,  8.3838,  1.0000,  8.3838],\n",
      "         [ 0.0000,  8.4848,  1.0000,  8.4848],\n",
      "         [ 0.0000,  8.5859,  1.0000,  8.5859],\n",
      "         [ 0.0000,  8.6869,  1.0000,  8.6869],\n",
      "         [ 0.0000,  8.7879,  1.0000,  8.7879],\n",
      "         [ 0.0000,  8.8889,  1.0000,  8.8889],\n",
      "         [ 0.0000,  8.9899,  1.0000,  8.9899],\n",
      "         [ 0.0000,  9.0909,  1.0000,  9.0909],\n",
      "         [ 0.0000,  9.1919,  1.0000,  9.1919],\n",
      "         [ 0.0000,  9.2929,  1.0000,  9.2929],\n",
      "         [ 0.0000,  9.3939,  1.0000,  9.3939],\n",
      "         [ 0.0000,  9.4949,  1.0000,  9.4949],\n",
      "         [ 0.0000,  9.5960,  1.0000,  9.5960],\n",
      "         [ 0.0000,  9.6970,  1.0000,  9.6970],\n",
      "         [ 0.0000,  9.7980,  1.0000,  9.7980],\n",
      "         [ 0.0000,  9.8990,  1.0000,  9.8990],\n",
      "         [ 0.0000, 10.0000,  1.0000, 10.0000]]])\n"
     ]
    }
   ],
   "source": [
    "data=torch.load('./ode_dataset/train_data.pt')\n",
    "#拿一组数据吧\n",
    "data=data[0,:,:]\n",
    "data=data.unsqueeze(0).float() #增加一个维度\n",
    "print(data.shape)\n",
    "dataset = TensorDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "for i,batch_data in enumerate(dataloader):\n",
    "    print(batch_data[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T11:44:53.488057Z",
     "start_time": "2023-07-19T11:44:53.390490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T04:47:47.742874Z",
     "start_time": "2023-07-20T04:47:47.736164Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "# 定义全局变量用于记录函数被调用的次数\n",
    "count_critic_step = 0\n",
    "count_generator_step = 0\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_critic_tensor_change(writer,loss,variable_t,in_fake_data:torch.Tensor,in_real_data:torch.Tensor):\n",
    "\n",
    "    global count_critic_step\n",
    "    count_critic_step+=1\n",
    "    # 开启交互模式\n",
    "    plt.ion()\n",
    "    in_fake_data=in_fake_data.detach().numpy()\n",
    "    in_fake_data=in_fake_data.reshape(100,1)\n",
    "    in_real_data=in_real_data.detach().numpy()\n",
    "    in_real_data=in_real_data.reshape(100,1)\n",
    "    plt.figure(1)\n",
    "    loss=loss.item()\n",
    "    #看一个维度上最大和最小值\n",
    "    plt.scatter(x=variable_t,y=in_fake_data,c='r',label='t-fake_data_critic')\n",
    "    plt.scatter(x=variable_t,y=in_real_data,c='b',label='t-real_data')\n",
    "    plt.legend()\n",
    "    # 保存图形，并设置标题loss\n",
    "    path=\"./tb_info/animation_csv/critic\"+\" \"+str(count_critic_step)+\".png\"\n",
    "    plt.title(\"critic_loss:\"+str(loss))\n",
    "    plt.savefig(path)\n",
    "    #legend 图例\n",
    "    plt.close()  # 清除窗口\n",
    "    image = Image.open(path)\n",
    "    image_tensor = ToTensor()(image)\n",
    "    print(image)\n",
    "    writer.add_image('critic_Image', image_tensor,global_step=count_critic_step)\n",
    "\n",
    "def plot_generator_tensor_change(writer,loss,variable_t,in_fake_data:torch.Tensor,in_real_data:torch.Tensor):\n",
    "    global count_generator_step\n",
    "    count_generator_step+=1\n",
    "    # 开启交互模式\n",
    "    plt.ion()\n",
    "    variable_t=variable_t.detach().numpy()\n",
    "    variable_t=variable_t.reshape(100,1)\n",
    "    in_fake_data=in_fake_data.detach().numpy()\n",
    "    in_fake_data=in_fake_data.reshape(100,1)\n",
    "    in_real_data=in_real_data.detach().numpy()\n",
    "    in_real_data=in_real_data.reshape(100,1)\n",
    "    plt.figure(1)\n",
    "    loss=loss.item()\n",
    "\n",
    "    #看一个维度上最大和最小值\n",
    "    plt.scatter(x=variable_t,y=in_fake_data,c='r',label='t-fake_data_generator')\n",
    "    plt.scatter(x=variable_t,y=in_real_data,c='b',label='t-real_data')\n",
    "    plt.legend()\n",
    "    # 保存图形，并设置标题loss\n",
    "    path=\"./tb_info/animation_csv/genertor\"+\" \"+str(count_generator_step)+\".png\"\n",
    "    plt.title(\"generator_loss:\"+str(loss))\n",
    "    plt.savefig(path)\n",
    "    plt.close()  # 清除窗口\n",
    "    image = Image.open(path)\n",
    "    image_tensor = ToTensor()(image)\n",
    "    print(image)\n",
    "    writer.add_image('generartor_Image', image_tensor,global_step=count_generator_step)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T04:47:48.082994Z",
     "start_time": "2023-07-20T04:47:48.073705Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "\n",
    " # 定义生成器“基的系数网络”, 输入是一维度的噪声，输出是[100,1]的解\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(301, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "    #kaiming 初始化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.kaiming_normal_(m.weight,a=0,mode='fan_in')\n",
    "    coeff=0 #基系数\n",
    "    energy=0 #消耗的energy\n",
    "\n",
    "    def create_matrix(self,data_t): #矩阵function\n",
    "\n",
    "        data_numpy=data_t.clone().numpy()\n",
    "        # 创建符号变量\n",
    "        x = sp.symbols('x')\n",
    "        # 构建运算矩阵\n",
    "        matrix = sp.Matrix([x**i for i in range(4)])\n",
    "        # 输入 x 的值 100*1的值\n",
    "        matrix_fn=sp.lambdify([x], matrix,'numpy')\n",
    "        # 计算矩阵的值\n",
    "        result = matrix_fn(data_numpy)\n",
    "        # 打印函数的符号表示\n",
    "        f_symbolic = sp.pretty(matrix)\n",
    "        return result[1][0],result[2][0],result[3][0]#返回三个列，表示生成的列，这里数值为1的列没有返回，后面有*vector，后期待优化\n",
    "\n",
    "    def print_coeff(self):\n",
    "        print('coeff is',self.coeff)\n",
    "        return self.coeff\n",
    "\n",
    "    def calculate_generate(self,coeff,data_t): #计算生成的函数\n",
    "        #print(coeff)\n",
    "        # 创建符号变量\n",
    "        #构建100*1的numpy\n",
    "        num_matirx=np.ones((4,100,1))\n",
    "        num_matirx[1,:,:],num_matirx[2,:,:],num_matirx[3,:,:]=self.create_matrix(data_t)\n",
    "        #print(num_matirx.shape)\n",
    "        num_matirx_tensor=num_matirx.astype(np.float32)\n",
    "        num_matirx_tensor=torch.from_numpy(num_matirx)\n",
    "        #四列加起来成为一列\n",
    "        generate_data=coeff[0,0]*data_t \\\n",
    "                      #+coeff[0,1]*num_matirx_tensor[1,:,:]\\\n",
    "                      # +0*coeff[0,2]*num_matirx_tensor[2,:,:]\\\n",
    "                      # +0*coeff[0,3]*num_matirx_tensor[3,:,:]\n",
    "        #data_t用二范数\n",
    "        # 计算一列数据的二范数 作为能量\n",
    "        energy=torch.norm(data_t)\\\n",
    "               +torch.norm(num_matirx_tensor[1,:,:])\\\n",
    "               +torch.norm(num_matirx_tensor[2,:,:])\\\n",
    "               +torch.norm(num_matirx_tensor[3,:,:])\n",
    "        return generate_data\n",
    "\n",
    "    def forward(self, x,data_t):\n",
    "        self.coeff=self.model(x)\n",
    "\n",
    "        data=self.calculate_generate(self.coeff,data_t)\n",
    "        return data\n",
    "\n",
    "# 定义判别器网络 输入是【ini_con,t,ydot,y】，输出是一个数-打分\n",
    "#[100,4]\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 100),\n",
    "        )\n",
    "         #kaiming 初始化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.kaiming_normal_(m.weight,a=0,mode='fan_in')\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T04:47:59.669855Z",
     "start_time": "2023-07-20T04:47:59.664533Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T04:49:59.380201Z",
     "start_time": "2023-07-20T04:49:59.376417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-238.6468, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x60BCF9F30>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.4998, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x2CFFF5E10>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5009, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x6C886C040>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5021, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5957508B0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5033, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x60BCFB010>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5047, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x8A7066860>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5061, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x92674D5D0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5077, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x95DC1C7F0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5094, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x95DC78490>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5110, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4FBEE4FA0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5128, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x666E04E20>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5148, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x666DD7E80>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5169, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x666D39AE0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5192, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5A211D4B0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5217, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5A21707F0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5243, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x53BC69FF0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5272, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x53BC4F610>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5303, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x53BCA6A70>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5336, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4FACAE2F0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5370, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x6C1C962F0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5406, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4FAC18C10>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5445, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x6C1CD70D0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5485, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x926660A90>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5527, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x8E6531A80>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5573, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x8E6552C50>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5621, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x8E658E320>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5674, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x31A55AD40>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5730, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x31A5B50F0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5790, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x31A534A30>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5855, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x32898A2F0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5925, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x33810BF70>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.5999, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5C9483B80>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.6078, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x33C4AC1C0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.6164, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x33C4CFDC0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.6254, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x29FA82EC0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.6349, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x29FADF1C0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.6451, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x29FAFC190>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.6560, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x32E3AA6B0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.6674, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x32E3011B0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.6796, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x31BEB5090>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.6925, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x31AD01270>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.7061, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5E1961FF0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.7205, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x7EC3FA860>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.7358, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x7EC36DDE0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.7518, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x7EC376E60>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.7687, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x33B449030>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.7866, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x33B436140>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.8054, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x33B4E1780>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.8252, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x2E85FF4C0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.8462, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x8960584F0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.8680, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x896027C70>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.8914, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x897F57B80>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.9158, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x897F4AE00>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.9414, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x29D8BD8D0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.9682, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x29D8F47F0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-33.9966, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x29D8E8D30>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.0266, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x618A90790>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.0581, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x347146200>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.0913, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x618AC79D0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.1256, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x662C447F0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.1625, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x662C39CC0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.2009, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3CCF1D300>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.2411, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3CCFE0820>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.2835, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3CCF15060>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.3275, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x39A241480>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.3736, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x838429570>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.4226, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x8384769E0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.4732, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3BEE51F90>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.5259, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3BEF01630>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.5806, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3BEE9CA90>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.6385, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x42A178280>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.6991, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x895BBFA60>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.7618, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x42A12AC80>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.8277, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x8A62EDED0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.8965, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x8A621BD00>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-34.9681, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x58E48D000>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.0409, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x58E44B160>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.1179, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x58E47C820>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.1991, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x47F29A950>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.2827, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5F3593B80>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.3688, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5F360A6B0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.4592, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5751FDCC0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.5535, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x575100DC0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.6503, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4D8730940>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.7519, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x60BE7AA70>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.8578, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4D87EE320>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-35.9660, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x8102D3760>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.0791, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4A07FA740>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.1966, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4A0748D00>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.3189, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4A3FB13C0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.4468, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4EAC37D90>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.5775, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4A3F02950>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.7114, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x86D553340>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.8543, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3012D8820>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.9991, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x86D5CE080>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.1502, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3AF3599C0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.3051, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3AF335090>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.4676, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3AF39F070>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.6325, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x61BBF04C0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.8045, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x87DA68520>\n",
      "fake_y_data shape torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "gloss_梯度地址 tensor(0.3891, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x628CD7A30>\n",
      "coeff is tensor([[2.0679]], grad_fn=<AddmmBackward0>)\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.2446, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x40A0D63E0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.3528, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x40A084790>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.4707, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x526E74C40>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.5878, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x7E9E09A50>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.7074, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x4084B5900>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.8305, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x643141AE0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-36.9615, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x53B7FDDB0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.0928, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x95C644160>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.2276, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x374AEF2B0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.3641, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5E77CE140>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.5076, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5E77A4520>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.6549, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5E7704C40>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.8080, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x698D08550>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-37.9596, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5B96CD330>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-38.1170, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x319A5C4C0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-38.2775, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x95A461330>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-38.4482, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x95A445B40>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-38.6188, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x923F68160>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-38.7936, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x923F10C40>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-38.9770, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x3B85175B0>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-39.1621, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x5A69F9C00>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-39.3500, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x815F43730>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-39.5452, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x815F40940>\n",
      "real_y_data_shape torch.Size([1, 100])\n",
      "fake_y_data* torch.Size([100, 1])\n",
      "fake_y_data* torch.Size([1, 100])\n",
      "real_y_data* torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "tensor(-39.7414, grad_fn=<NegBackward0>)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480 at 0x2A7466200>\n",
      "real_y_data_shape torch.Size([1, 100])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[148], line 51\u001B[0m\n\u001B[1;32m     49\u001B[0m real_data_t\u001B[38;5;241m=\u001B[39mreal_data_t\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m#生成假的y数据 要detach\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m fake_y_data \u001B[38;5;241m=\u001B[39m \u001B[43mgenerator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mreal_data_t\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfake_y_data*\u001B[39m\u001B[38;5;124m\"\u001B[39m,fake_y_data\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     53\u001B[0m fake_y_data\u001B[38;5;241m=\u001B[39mfake_y_data\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m100\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[147], line 63\u001B[0m, in \u001B[0;36mGenerator.forward\u001B[0;34m(self, x, data_t)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x,data_t):\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoeff\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(x)\n\u001B[0;32m---> 63\u001B[0m     data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcalculate_generate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdata_t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "Cell \u001B[0;32mIn[147], line 43\u001B[0m, in \u001B[0;36mGenerator.calculate_generate\u001B[0;34m(self, coeff, data_t)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate_generate\u001B[39m(\u001B[38;5;28mself\u001B[39m,coeff,data_t): \u001B[38;5;66;03m#计算生成的函数\u001B[39;00m\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;66;03m#print(coeff)\u001B[39;00m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;66;03m# 创建符号变量\u001B[39;00m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;66;03m#构建100*1的numpy\u001B[39;00m\n\u001B[1;32m     42\u001B[0m     num_matirx\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mones((\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m100\u001B[39m,\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m---> 43\u001B[0m     num_matirx[\u001B[38;5;241m1\u001B[39m,:,:],num_matirx[\u001B[38;5;241m2\u001B[39m,:,:],num_matirx[\u001B[38;5;241m3\u001B[39m,:,:]\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;66;03m#print(num_matirx.shape)\u001B[39;00m\n\u001B[1;32m     45\u001B[0m     num_matirx_tensor\u001B[38;5;241m=\u001B[39mnum_matirx\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "Cell \u001B[0;32mIn[147], line 27\u001B[0m, in \u001B[0;36mGenerator.create_matrix\u001B[0;34m(self, data_t)\u001B[0m\n\u001B[1;32m     25\u001B[0m matrix \u001B[38;5;241m=\u001B[39m sp\u001B[38;5;241m.\u001B[39mMatrix([x\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mi \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m4\u001B[39m)])\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# 输入 x 的值 100*1的值\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m matrix_fn\u001B[38;5;241m=\u001B[39m\u001B[43msp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlambdify\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmatrix\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnumpy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# 计算矩阵的值\u001B[39;00m\n\u001B[1;32m     29\u001B[0m result \u001B[38;5;241m=\u001B[39m matrix_fn(data_numpy)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sympy/utilities/lambdify.py:898\u001B[0m, in \u001B[0;36mlambdify\u001B[0;34m(args, expr, modules, printer, use_imps, dummify, cse)\u001B[0m\n\u001B[1;32m    896\u001B[0m sig \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunc(\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(i) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m names))\n\u001B[1;32m    897\u001B[0m sig \u001B[38;5;241m=\u001B[39m textwrap\u001B[38;5;241m.\u001B[39mfill(sig, subsequent_indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m8\u001B[39m)\n\u001B[0;32m--> 898\u001B[0m expr_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mexpr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    899\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(expr_str) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m78\u001B[39m:\n\u001B[1;32m    900\u001B[0m     expr_str \u001B[38;5;241m=\u001B[39m textwrap\u001B[38;5;241m.\u001B[39mwrap(expr_str, \u001B[38;5;241m75\u001B[39m)[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sympy/matrices/matrices.py:852\u001B[0m, in \u001B[0;36mMatrixBase.__str__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m S\u001B[38;5;241m.\u001B[39mZero \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape:\n\u001B[1;32m    851\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMatrix(\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, [])\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrows, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcols)\n\u001B[0;32m--> 852\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMatrix(\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sympy/core/_print_helpers.py:29\u001B[0m, in \u001B[0;36mPrintable.__str__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__str__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprinting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstr\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sstr\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msstr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sympy/printing/printer.py:372\u001B[0m, in \u001B[0;36m_PrintFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 372\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__wrapped__\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sympy/printing/str.py:999\u001B[0m, in \u001B[0;36msstr\u001B[0;34m(expr, **settings)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;129m@print_function\u001B[39m(StrPrinter)\n\u001B[1;32m    983\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msstr\u001B[39m(expr, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msettings):\n\u001B[1;32m    984\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns the expression as a string.\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \n\u001B[1;32m    986\u001B[0m \u001B[38;5;124;03m    For large expressions where speed is a concern, use the setting\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    996\u001B[0m \u001B[38;5;124;03m    'Eq(a + b, 0)'\u001B[39;00m\n\u001B[1;32m    997\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 999\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[43mStrPrinter\u001B[49m\u001B[43m(\u001B[49m\u001B[43msettings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1000\u001B[0m     s \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mdoprint(expr)\n\u001B[1;32m   1002\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m s\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sympy/printing/printer.py:258\u001B[0m, in \u001B[0;36mPrinter.__init__\u001B[0;34m(self, settings)\u001B[0m\n\u001B[1;32m    255\u001B[0m             settings[key] \u001B[38;5;241m=\u001B[39m val\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m settings\n\u001B[0;32m--> 258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, settings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_settings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_initial_settings()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "# 创建一个 SummaryWriter 对象，指定保存日志的目录\n",
    "writer = SummaryWriter('./tb_info/logs')\n",
    "# 初始化生成器和判别器\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# 优化器,  固定学习率1e-3\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=1e-4)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "# 获取一个批次的数据\n",
    "batch_data = next(iter(dataloader))\n",
    "# 训练生成器每n_generator步\n",
    "n_generator=100\n",
    "# 训练生成器每n_critic步\n",
    "n_critic=1\n",
    "beta=0\n",
    "# 训练GAN模型\n",
    "num_epochs = 10000\n",
    "noise_dim = 1  # 噪声向量的维度\n",
    "mean = 0.0  # 高斯分布的均值\n",
    "stddev = 0.01   # 高斯分布的标准差\n",
    "Dict_G={\"train_critic_fake_y\":torch.tensor([]),\n",
    "        \"train_self\":torch.tensor([])}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,batch_data in enumerate(dataloader,0):#索引值将从 0 开始递增，依次对应每个批次的位置。\n",
    "        # 训练判别器\n",
    "        real_data=batch_data[0].float()\n",
    "        real_y_data=real_data[:,:,3]\n",
    "        condition_data=real_data[:,:,0:3].float()\n",
    "        condition_data=condition_data.reshape(-1,300)\n",
    "        print(\"real_y_data_shape\",real_y_data.shape)#【1,100,4】\n",
    "        # 定义噪声向量的大小和分布参数\n",
    "        z = torch.randn((1,noise_dim))*stddev+mean#1*noise_dim\n",
    "        z_condition=torch.cat((z,condition_data),dim=1)#1*（noise_dim+300）\n",
    "        #这里也记录一下采样的噪声值\n",
    "        writer.add_scalar('train_critic_z', z, epoch)\n",
    "        real_data_t=real_data[:,:,1]#变量t\n",
    "        real_data_t=real_data_t.reshape(-1,1)\n",
    "        #生成假的y数据 要detach\n",
    "        fake_y_data = generator(z_condition.detach(),real_data_t.detach()).float()\n",
    "        print(\"fake_y_data*\",fake_y_data.shape)\n",
    "        fake_y_data=fake_y_data.view(1,100)\n",
    "        print(\"fake_y_data*\",fake_y_data.shape)\n",
    "        print(\"real_y_data*\",real_y_data.shape)\n",
    "        #压缩成一列\n",
    "\n",
    "        #real_scores = discriminator(real_y_data)\n",
    "        fake_scores = discriminator(fake_y_data)\n",
    "\n",
    "        # 计算判别器损失\n",
    "        #d_loss =fake_scores-real_scores#神经网络打分器\n",
    "\n",
    "        d_loss=-torch.nn.MSELoss()(fake_scores,real_y_data)#神经网络打分器\n",
    "        print(d_loss)\n",
    "        plot_critic_tensor_change(writer,d_loss,real_data_t,fake_y_data,real_y_data)\n",
    "\n",
    "        # 反向传播和更新判别器的参数\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        #梯度截断\n",
    "        for p in discriminator.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "    writer.add_scalars('losses', {'critic':d_loss.item()}\n",
    "                                         , epoch)#记录\n",
    "\n",
    "        # 训练生成器\n",
    "        #取余\n",
    "    if((epoch+1)%n_generator)==0:#训练生成器\n",
    "            # -----------------\n",
    "            #  训练生成器\n",
    "            # -----------------\n",
    "            optimizer_g.zero_grad()\n",
    "\n",
    "            data_t=real_data[:,:,1].detach()#变量t\n",
    "            condition_data=real_data[:,:,0:3].float()\n",
    "            condition_data=condition_data.reshape(-1,300)\n",
    "            data_t=data_t.reshape(-1,1) #[100,1]\n",
    "\n",
    "            supervisor_y=real_data[:,:,3]#\n",
    "            supervisor_y=supervisor_y.reshape(100,1)\n",
    "\n",
    "            # 生成噪声作为生成器输入\n",
    "            z = torch.randn((1,noise_dim))*stddev+mean#1*noise_dim#噪声\n",
    "            z_condition=torch.cat((z,condition_data),dim=1)#1*（noise_dim+300）\n",
    "            # 生成器输出\n",
    "            fake_y_data = generator(z_condition.detach(),data_t.detach())\n",
    "            fake_y_data=fake_y_data\n",
    "            fake_y_data=fake_y_data.view(1,100)\n",
    "            print(\"fake_y_data shape\",fake_y_data.shape)\n",
    "\n",
    "            supervisor_y=supervisor_y.reshape(100,1)\n",
    "\n",
    "            g_loss = -torch.mean(discriminator(fake_y_data.float()))\n",
    "            print(\"gloss_梯度地址\",g_loss)\n",
    "            plot_generator_tensor_change(writer,g_loss,data_t,fake_y_data,supervisor_y)\n",
    "\n",
    "\n",
    "            writer.add_scalars('losses', {'generator':g_loss.item()}\n",
    "                                         , epoch)#记录\n",
    "            #记录一下 训练生成器的系数\n",
    "            coeff=generator.print_coeff()\n",
    "            writer.add_scalars('trian_generator_coeff',\n",
    "                                     {'alpha1':coeff[0,0].item(),\n",
    "                                     #'alpha2':coeff[0,1].item(),\n",
    "                                     # 'alpha3':coeff[0,2].item(),\n",
    "                                      #'alpha4':coeff[0,3].item()\n",
    "                                      }\n",
    "                                         , epoch)#记录\n",
    "\n",
    "            #反向传播\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "    # 关闭 SummaryWriter\n",
    "    writer.close()\n",
    " #每个epoch结束后打印损失\n",
    "    #print(f\"Epoch [{epoch+1}/{num_epochs}], Generator Loss: {g_loss.item():.4f}, Discriminator Loss: {d_loss.item():.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T04:48:19.615746Z",
     "start_time": "2023-07-20T04:48:08.488143Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T01:22:35.877715Z",
     "start_time": "2023-07-20T01:22:35.872743Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T11:47:01.318448Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 输入噪声\n",
    "z = torch.randn((1,noise_dim))*stddev+mean#1*noise_dim\n",
    "print(z)\n",
    "data_t=torch.linspace(0,10,100)\n",
    "\n",
    "data_t=data_t.reshape(-1,1)\n",
    "fake_data = generator(z,data_t)\n",
    "generator.print_coeff()\n",
    "a=fake_data.detach().numpy()\n",
    "# 画出生成器生成的数据分布\n",
    "plt.plot(data_t,a[:,0],label='G(t)')\n",
    "plt.plot(data_t,data[0,:,3],label='raw(t)')\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T11:47:01.319634Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "t加入的噪声z,最后影响函数\n",
    "对initial condition加扰动\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:54.145784Z",
     "start_time": "2023-07-18T12:25:54.057765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0031]])\n",
      "coeff is tensor([[ 0.8460, -0.0822,  0.0719, -0.0051]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x89b4de290>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5519, 3.1675]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义张量的大小\n",
    "rows = 1\n",
    "cols = 2\n",
    "\n",
    "# 定义噪声的均值和方差\n",
    "mean = 0\n",
    "variance = 4\n",
    "std_dev = torch.sqrt(torch.tensor([variance]))  # 标准差是方差的平方根\n",
    "\n",
    "# 使用 PyTorch 生成二维的噪声\n",
    "noise = torch.randn(rows, cols) * std_dev + mean  # 将噪声调整为具有所需的均值和方差\n",
    "\n",
    "print(noise)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T07:41:54.252347Z",
     "start_time": "2023-07-13T07:41:54.245425Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.7067, -1.5636]])\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:54.146178Z",
     "start_time": "2023-07-18T12:25:54.062591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
