{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:11:48.719885Z",
     "start_time": "2023-10-17T11:11:48.654700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## this for package import and data prepare"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "outputs": [],
   "source": [
    "\n",
    "import utlis_2nd.cusdom as custom\n",
    "import super_learn_task_expr2 as expr2\n",
    "import warnings\n",
    "\n",
    "read_abso_path=\"/Users/liangaoming/Documents/Ai_station/neural_find_sol/wgan_2nd/complex_center_dataset/combined_data.pt\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import namedtuple\n",
    "# 定义 Transition\n",
    "Transition = namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "# 创建一个 Transition 对象\n",
    "trans = Transition(state=1, action=2, reward=3, next_state=4, done=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:11:49.070295Z",
     "start_time": "2023-10-17T11:11:49.024353Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data & read yaml\n",
      "shape: torch.Size([256, 100, 9])\n",
      "label for csv: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# split data & get the t_steps\n",
    "train_loader,valid_loader,test_loader,yaml_config =\\\n",
    "    custom.return_train_valid_test4loader(abso_path=read_abso_path)\n",
    "# look（shape）\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(\"shape:\", data.shape)\n",
    "    print(\"label for csv:\",target.shape)\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:11:50.699946Z",
     "start_time": "2023-10-17T11:11:49.199055Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the omega_neural network from nn_base\n",
    "\n",
    "## Here: we just to evaluate the\n",
    "### 1.omega_neural network\n",
    "input_shape: the shape means that we have 100 time steps and 2 variables input **[-1,100,2]**\n",
    "output_shape: output **[-1,51,2]**\n",
    "### 2.inference_neural network\n",
    "input_shape: the shape means that we have 100 time steps and 2 variables input **[-1，100，2]**\n",
    "output_shape: output **[-1,100,2]**\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "outputs": [],
   "source": [
    "results_path= \"/Users/liangaoming/Documents/Ai_station/neural_find_sol/wgan_2nd/expr2/expr2_results/expr2_\"\n",
    "expr2.config[\"train_nomin\"]= int((yaml_config['train_size_percent']*yaml_config['all_solus_numbers'])/yaml_config[\"batch_size\"])\n",
    "expr2.config[\"valid_nomin\"]= int((yaml_config['valid_size_percent']*yaml_config['all_solus_numbers'])/yaml_config[\"batch_size\"])\n",
    "expr2.config[\"test_nomin\"]= int((yaml_config['test_size_percent']*yaml_config['all_solus_numbers'])/yaml_config[\"batch_size\"])\n",
    "expr2.config[\"train_loader\"]= train_loader\n",
    "expr2.config[\"valid_loader\"]= valid_loader\n",
    "expr2.config[\"test_loader\"]= test_loader\n",
    "expr2.config[\"data_length\"]= yaml_config[\"data_length\"]\n",
    "expr2.config[\"device\"] = \"cpu\"\n",
    "expr2.config[\"hidden_act\"]= \"rational\"\n",
    "expr2.config[\"inference_output_act\"]=\"identity\"\n",
    "expr2.config[\"omega_output_act\"]=\"softmax\"\n",
    "expr2.config[\"inference_output_act\"]=\"Identity\"\n",
    "expr2.config[\"vari_number\"]= yaml_config[\"vari_number\"]\n",
    "expr2.config[\"sample_vesting\"]=2 #2s\n",
    "expr2.config[\"Inference_num_epoch\"]=100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:11:50.764873Z",
     "start_time": "2023-10-17T11:11:50.703665Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prior knowledge is {'basis_1': 'x**0', 'basis_2': 'sin', 'basis_3': 'cos'}\n",
      "output_dim 202\n",
      "output_act is Identity\n",
      "hi\n",
      "test_only_inference\n",
      "start train_inference\n",
      "Sample_index torch.Size([256, 3])\n",
      "gather_befor torch.Size([256, 51])\n",
      "Sample_index torch.Size([256, 3])\n",
      "result tensor([[ 3.4650,  1.9800, 10.8900],\n",
      "        [ 0.9900,  3.9600,  1.4850],\n",
      "        [ 0.9900, 23.2650,  0.4950],\n",
      "        [ 2.4750,  0.9900, 14.8500],\n",
      "        [19.8000,  0.9900,  1.9800],\n",
      "        [ 0.9900,  2.9700, 21.7800],\n",
      "        [10.3950,  1.4850,  2.4750],\n",
      "        [ 1.9800, 19.3050,  8.4150],\n",
      "        [ 1.4850,  9.4050,  2.4750],\n",
      "        [ 0.4950,  1.4850,  0.9900],\n",
      "        [ 1.9800,  1.4850, 17.8200],\n",
      "        [ 1.4850,  3.9600,  2.4750],\n",
      "        [ 1.9800,  0.9900,  1.4850],\n",
      "        [ 1.9800,  9.9000,  0.9900],\n",
      "        [ 1.4850,  2.4750,  0.9900],\n",
      "        [ 1.9800, 21.2850, 19.3050],\n",
      "        [ 1.4850,  0.9900,  1.9800],\n",
      "        [ 1.9800, 16.3350,  6.4350],\n",
      "        [ 0.9900,  0.4950,  1.9800],\n",
      "        [ 1.9800,  1.4850,  0.9900],\n",
      "        [ 2.9700,  9.4050,  0.9900],\n",
      "        [ 3.9600,  1.9800,  3.4650],\n",
      "        [ 1.9800,  0.9900,  1.4850],\n",
      "        [ 1.9800,  0.4950,  2.4750],\n",
      "        [ 1.4850, 20.2950, 21.2850],\n",
      "        [ 1.9800,  3.4650,  9.9000],\n",
      "        [ 1.4850, 11.8800, 12.8700],\n",
      "        [ 7.4250,  2.4750,  1.9800],\n",
      "        [ 2.4750,  0.9900,  4.4550],\n",
      "        [ 0.4950,  2.4750,  6.4350],\n",
      "        [ 0.4950,  3.9600,  1.9800],\n",
      "        [ 0.9900,  7.4250,  9.4050],\n",
      "        [ 5.4450,  1.4850,  0.9900],\n",
      "        [ 0.4950, 21.7800,  1.4850],\n",
      "        [ 0.4950,  2.4750,  1.9800],\n",
      "        [ 1.9800,  2.4750,  4.9500],\n",
      "        [ 1.9800, 22.7700,  1.4850],\n",
      "        [ 1.9800,  1.4850,  6.4350],\n",
      "        [ 2.9700,  1.9800,  5.9400],\n",
      "        [ 1.9800,  2.4750,  4.4550],\n",
      "        [20.2950, 14.3550,  1.9800],\n",
      "        [ 2.4750,  1.9800,  1.4850],\n",
      "        [19.8000,  3.9600, 18.3150],\n",
      "        [17.3250,  1.9800,  1.4850],\n",
      "        [11.8800,  0.4950,  0.9900],\n",
      "        [ 0.4950,  1.9800,  2.4750],\n",
      "        [ 0.4950,  0.9900,  2.4750],\n",
      "        [ 0.9900,  3.4650,  7.4250],\n",
      "        [ 0.9900,  1.9800,  2.4750],\n",
      "        [ 1.4850,  2.9700, 18.8100],\n",
      "        [ 2.4750,  0.9900,  5.9400],\n",
      "        [ 3.9600,  1.9800,  0.9900],\n",
      "        [ 0.9900,  0.4950,  3.4650],\n",
      "        [ 0.9900,  1.4850,  8.9100],\n",
      "        [ 1.4850,  1.9800,  9.4050],\n",
      "        [ 1.4850,  4.9500, 11.8800],\n",
      "        [ 8.9100, 21.7800,  4.4550],\n",
      "        [ 1.4850,  0.4950,  2.9700],\n",
      "        [ 1.9800,  2.4750,  7.9200],\n",
      "        [ 2.4750,  1.9800,  0.9900],\n",
      "        [ 1.4850,  0.9900,  2.4750],\n",
      "        [ 1.9800,  1.4850,  2.9700],\n",
      "        [12.3750,  0.9900,  1.4850],\n",
      "        [ 1.4850,  0.9900,  1.9800],\n",
      "        [ 1.9800,  2.4750,  0.9900],\n",
      "        [ 1.4850, 14.8500,  1.9800],\n",
      "        [ 0.4950,  1.9800,  2.4750],\n",
      "        [ 2.4750,  1.9800,  0.9900],\n",
      "        [ 1.9800,  2.9700,  4.9500],\n",
      "        [ 1.9800,  7.9200, 24.7500],\n",
      "        [ 0.9900,  1.4850,  0.4950],\n",
      "        [ 0.9900,  0.4950,  1.9800],\n",
      "        [ 2.4750,  1.4850, 12.8700],\n",
      "        [ 0.9900,  1.9800, 13.8600],\n",
      "        [12.3750, 14.3550, 10.8900],\n",
      "        [ 1.9800,  6.4350, 17.8200],\n",
      "        [20.2950,  0.4950,  0.9900],\n",
      "        [ 1.9800,  1.4850, 13.8600],\n",
      "        [11.3850, 11.8800, 10.8900],\n",
      "        [ 9.4050,  1.9800,  4.4550],\n",
      "        [ 2.4750,  3.9600,  1.9800],\n",
      "        [ 1.4850,  0.4950, 10.3950],\n",
      "        [ 1.9800,  0.9900,  2.4750],\n",
      "        [ 0.9900,  1.4850,  1.9800],\n",
      "        [ 1.4850,  0.9900,  1.9800],\n",
      "        [ 1.9800,  2.4750,  5.4450],\n",
      "        [ 8.4150,  3.4650,  1.9800],\n",
      "        [11.8800,  0.4950,  0.9900],\n",
      "        [ 4.4550,  3.4650,  1.9800],\n",
      "        [ 1.4850,  0.9900,  0.4950],\n",
      "        [ 1.9800,  1.4850,  7.9200],\n",
      "        [ 0.4950,  0.9900, 12.8700],\n",
      "        [ 1.4850,  4.4550,  1.9800],\n",
      "        [ 0.4950,  2.4750, 15.3450],\n",
      "        [ 3.9600,  0.9900,  0.4950],\n",
      "        [ 1.9800, 15.3450, 11.8800],\n",
      "        [ 1.9800,  8.9100,  2.4750],\n",
      "        [ 2.4750,  0.9900,  1.9800],\n",
      "        [ 1.4850,  2.4750,  5.9400],\n",
      "        [ 3.9600,  1.9800,  0.9900],\n",
      "        [ 1.9800, 12.8700,  1.4850],\n",
      "        [ 0.9900,  1.4850,  0.4950],\n",
      "        [21.7800,  0.9900,  1.9800],\n",
      "        [ 2.4750,  0.9900,  5.9400],\n",
      "        [ 2.4750,  1.4850,  1.9800],\n",
      "        [ 1.4850,  2.4750, 10.3950],\n",
      "        [ 1.9800,  4.9500, 20.2950],\n",
      "        [21.2850,  1.9800, 22.7700],\n",
      "        [ 1.4850,  3.9600,  1.9800],\n",
      "        [ 0.9900,  3.9600,  2.4750],\n",
      "        [13.8600,  4.4550,  0.9900],\n",
      "        [ 3.9600,  0.9900,  3.4650],\n",
      "        [ 2.9700,  1.9800,  9.9000],\n",
      "        [ 1.4850, 18.8100,  3.4650],\n",
      "        [ 1.9800, 24.2550,  2.4750],\n",
      "        [ 0.4950,  3.4650,  1.4850],\n",
      "        [ 0.9900,  1.9800,  2.9700],\n",
      "        [ 1.4850,  0.9900,  1.9800],\n",
      "        [ 6.4350,  0.4950,  1.4850],\n",
      "        [ 1.9800,  2.9700,  1.4850],\n",
      "        [17.8200, 14.8500, 11.3850],\n",
      "        [ 0.9900,  3.9600,  4.4550],\n",
      "        [ 3.4650,  1.9800,  1.4850],\n",
      "        [ 2.4750,  1.4850, 16.8300],\n",
      "        [ 0.9900,  5.4450,  1.4850],\n",
      "        [ 1.4850,  0.9900,  4.4550],\n",
      "        [ 3.4650, 12.8700,  1.9800],\n",
      "        [ 4.9500,  0.9900,  0.4950],\n",
      "        [ 1.9800, 23.2650,  2.9700],\n",
      "        [ 1.4850,  0.9900, 10.8900],\n",
      "        [ 4.4550,  1.9800, 19.8000],\n",
      "        [ 0.9900, 22.7700,  1.9800],\n",
      "        [ 0.4950,  1.9800,  6.9300],\n",
      "        [ 1.9800, 18.3150,  5.9400],\n",
      "        [16.3350,  1.9800,  1.4850],\n",
      "        [ 1.9800,  0.9900, 20.7900],\n",
      "        [ 2.9700,  2.4750,  0.4950],\n",
      "        [ 5.4450,  3.4650, 19.3050],\n",
      "        [ 0.9900,  3.4650,  2.4750],\n",
      "        [ 1.4850,  2.4750,  4.9500],\n",
      "        [ 2.4750,  1.4850,  1.9800],\n",
      "        [ 2.9700,  1.4850,  0.4950],\n",
      "        [ 1.4850,  0.4950,  2.4750],\n",
      "        [ 2.9700,  2.4750,  0.9900],\n",
      "        [ 9.4050, 10.3950,  2.9700],\n",
      "        [ 0.9900,  7.9200,  6.9300],\n",
      "        [ 1.4850,  0.9900,  3.4650],\n",
      "        [10.8900,  1.4850,  7.4250],\n",
      "        [14.8500,  3.4650,  2.4750],\n",
      "        [ 2.4750,  1.4850,  1.9800],\n",
      "        [ 0.9900,  9.4050,  8.4150],\n",
      "        [23.2650,  6.9300,  1.4850],\n",
      "        [ 9.4050, 23.2650,  1.4850],\n",
      "        [ 0.9900,  3.4650, 18.8100],\n",
      "        [ 2.9700,  1.9800,  1.4850],\n",
      "        [ 1.4850,  2.9700,  2.4750],\n",
      "        [ 2.9700, 14.3550,  1.4850],\n",
      "        [22.7700, 10.8900,  0.9900],\n",
      "        [ 2.4750,  9.9000,  7.4250],\n",
      "        [ 1.9800, 19.3050,  2.4750],\n",
      "        [ 2.4750,  0.9900,  2.9700],\n",
      "        [15.8400,  3.9600, 18.3150],\n",
      "        [ 1.9800,  2.4750,  4.4550],\n",
      "        [ 1.9800,  3.4650,  6.4350],\n",
      "        [11.8800,  1.4850,  0.4950],\n",
      "        [11.8800,  0.9900,  0.4950],\n",
      "        [ 2.4750,  1.9800,  2.9700],\n",
      "        [ 9.9000,  6.9300,  1.4850],\n",
      "        [18.8100,  3.4650,  1.9800],\n",
      "        [ 4.9500,  0.4950,  1.4850],\n",
      "        [ 2.9700,  6.9300,  0.9900],\n",
      "        [ 1.9800,  3.4650, 10.8900],\n",
      "        [11.8800,  0.4950, 12.3750],\n",
      "        [ 2.9700,  2.4750,  1.4850],\n",
      "        [ 0.9900,  1.4850,  0.4950],\n",
      "        [ 0.9900,  0.4950,  1.4850],\n",
      "        [ 0.9900,  1.4850,  2.4750],\n",
      "        [ 1.4850,  1.9800,  5.4450],\n",
      "        [ 0.9900, 23.7600,  2.4750],\n",
      "        [ 1.9800,  2.4750,  1.4850],\n",
      "        [ 0.9900,  1.4850,  0.4950],\n",
      "        [ 1.9800,  4.9500,  1.4850],\n",
      "        [ 1.4850,  2.4750, 24.2550],\n",
      "        [ 1.4850,  0.9900,  1.9800],\n",
      "        [ 3.4650,  1.4850,  1.9800],\n",
      "        [11.3850,  1.9800, 16.8300],\n",
      "        [ 3.9600,  3.4650,  0.9900],\n",
      "        [ 8.9100,  0.4950,  0.9900],\n",
      "        [11.8800,  0.9900,  0.4950],\n",
      "        [ 1.9800,  2.9700,  6.4350],\n",
      "        [17.3250,  1.4850,  1.9800],\n",
      "        [ 0.4950,  3.9600,  0.9900],\n",
      "        [ 1.4850,  4.9500,  0.4950],\n",
      "        [16.8300, 24.2550,  2.4750],\n",
      "        [ 0.9900,  8.4150,  1.4850],\n",
      "        [ 4.4550, 19.3050,  0.9900],\n",
      "        [ 1.4850,  1.9800,  3.9600],\n",
      "        [ 1.9800,  0.9900,  1.4850],\n",
      "        [ 1.9800,  2.4750,  8.4150],\n",
      "        [ 0.9900,  6.4350,  2.4750],\n",
      "        [ 1.4850,  3.9600,  1.9800],\n",
      "        [ 0.4950,  0.9900, 12.3750],\n",
      "        [ 1.9800,  3.9600,  2.4750],\n",
      "        [ 2.4750, 18.3150,  4.9500],\n",
      "        [ 2.4750,  0.4950, 18.3150],\n",
      "        [ 1.9800, 12.3750, 21.7800],\n",
      "        [ 4.9500,  0.4950,  1.9800],\n",
      "        [ 0.9900,  0.4950,  2.4750],\n",
      "        [ 4.9500,  1.4850,  0.9900],\n",
      "        [ 1.4850, 15.3450,  0.9900],\n",
      "        [ 0.9900,  0.4950,  3.9600],\n",
      "        [ 5.4450,  1.4850,  0.9900],\n",
      "        [ 1.4850,  0.9900,  1.9800],\n",
      "        [16.8300,  1.9800, 10.3950],\n",
      "        [ 1.4850,  0.9900,  3.4650],\n",
      "        [ 0.9900, 17.8200,  1.4850],\n",
      "        [ 0.9900,  6.4350,  5.4450],\n",
      "        [ 2.4750,  0.9900, 23.2650],\n",
      "        [ 1.9800, 13.3650,  2.9700],\n",
      "        [ 7.4250,  1.4850,  8.4150],\n",
      "        [ 0.4950,  0.9900,  1.4850],\n",
      "        [ 0.4950,  1.4850,  3.9600],\n",
      "        [ 1.4850,  0.9900, 10.8900],\n",
      "        [ 0.4950,  1.9800, 22.2750],\n",
      "        [18.3150,  1.9800, 22.7700],\n",
      "        [ 0.4950,  0.9900,  6.4350],\n",
      "        [ 3.9600,  1.9800,  3.4650],\n",
      "        [ 0.9900, 11.8800,  5.9400],\n",
      "        [ 1.4850,  4.4550, 19.8000],\n",
      "        [16.3350, 10.3950,  0.9900],\n",
      "        [ 5.9400,  8.4150,  5.4450],\n",
      "        [ 1.4850,  1.9800,  2.4750],\n",
      "        [ 1.4850, 10.3950,  0.9900],\n",
      "        [ 3.9600,  0.9900,  6.9300],\n",
      "        [12.8700,  0.9900, 24.2550],\n",
      "        [ 0.9900, 10.8900, 10.3950],\n",
      "        [ 0.9900,  0.4950,  6.4350],\n",
      "        [ 0.4950,  1.4850,  0.9900],\n",
      "        [ 0.9900, 16.8300,  0.4950],\n",
      "        [ 7.4250,  5.4450, 11.8800],\n",
      "        [ 2.4750,  1.4850,  6.9300],\n",
      "        [ 1.9800, 16.8300,  0.4950],\n",
      "        [ 1.4850,  2.4750, 18.3150],\n",
      "        [ 0.9900,  3.9600,  1.4850],\n",
      "        [ 1.4850,  1.9800,  0.9900],\n",
      "        [ 1.4850,  0.4950,  0.9900],\n",
      "        [ 5.9400,  1.4850, 11.3850],\n",
      "        [ 2.9700,  4.4550,  1.9800],\n",
      "        [ 2.4750,  2.9700, 24.7500],\n",
      "        [ 1.4850,  7.9200, 14.8500],\n",
      "        [ 1.4850,  0.9900,  1.9800],\n",
      "        [15.3450,  1.9800,  1.4850],\n",
      "        [ 0.9900,  4.4550,  1.4850],\n",
      "        [ 1.9800,  0.4950,  0.9900],\n",
      "        [ 1.4850,  0.9900,  1.9800],\n",
      "        [17.8200,  0.4950,  5.4450]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[617], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# return test' results\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mexpr2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_expr\u001B[49m\u001B[43m(\u001B[49m\u001B[43m                          \u001B[49m\u001B[43mresults_save_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresults_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mfolder_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m97\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mtrain_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpr2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minference_net\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai_station/neural_find_sol/wgan_2nd/expr2/super_learn_task_expr2.py:302\u001B[0m, in \u001B[0;36mdo_expr\u001B[0;34m(results_save_path, folder_num, train_config, model_type)\u001B[0m\n\u001B[1;32m    300\u001B[0m record_init(folder_num\u001B[38;5;241m=\u001B[39mfolder_num,expr_data_path_new\u001B[38;5;241m=\u001B[39mresults_save_path)\n\u001B[1;32m    301\u001B[0m save_config(train_config)\n\u001B[0;32m--> 302\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mexpr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexpr_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai_station/neural_find_sol/wgan_2nd/expr2/super_learn_task_expr2.py:264\u001B[0m, in \u001B[0;36mexpr\u001B[0;34m(expr_config, train_type)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m (train_type\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minference_net\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhi\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 264\u001B[0m     \u001B[43mtrain_inference_actor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mco_train_actor\u001B[49m\u001B[43m,\u001B[49m\u001B[43mconfig_device\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpr_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdevice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    265\u001B[0m     test_dict\u001B[38;5;241m=\u001B[39mtest_inference_model(co_train_actor)\n\u001B[1;32m    267\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m test_dict,\\\n\u001B[1;32m    268\u001B[0m            co_train_actor\n",
      "File \u001B[0;32m~/Documents/Ai_station/neural_find_sol/wgan_2nd/expr2/super_learn_task_expr2.py:171\u001B[0m, in \u001B[0;36mtrain_inference_actor\u001B[0;34m(co_train_actor, config_device)\u001B[0m\n\u001B[1;32m    169\u001B[0m uf\u001B[38;5;241m.\u001B[39mset_seed(config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m#train the model\u001B[39;00m\n\u001B[0;32m--> 171\u001B[0m \u001B[43mco_train_actor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_inference_neural\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig_device\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai_station/neural_find_sol/utlis_2nd/co_train.py:79\u001B[0m, in \u001B[0;36mtrain_init.train_inference_neural\u001B[0;34m(self, process_name, device, save_2visualfig)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# inference loss\u001B[39;00m\n\u001B[1;32m     75\u001B[0m pred_coeffs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mS_I(real) \u001B[38;5;66;03m#[batch,freq_index*2,2]\u001B[39;00m\n\u001B[0;32m---> 79\u001B[0m left_matrix,pred_data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mS_I\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_pred_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred_coeffs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mreal_freq_distrubtion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m pred_freq_distrubtion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mS_I\u001B[38;5;241m.\u001B[39mreturn_fft_spectrum(pred_data,need_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m(save_2visualfig\u001B[38;5;241m==\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m~/Documents/Ai_station/neural_find_sol/utlis_2nd/neural_base_class.py:518\u001B[0m, in \u001B[0;36mOmgea_MLPwith_residual_dict.return_pred_data\u001B[0;34m(self, coeff_tensor, freq_distrubtion_tensor, Sample_choice, prob_sample_numb)\u001B[0m\n\u001B[1;32m    512\u001B[0m     z2_left_matirx[:, :, \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exprs \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msin\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    516\u001B[0m \n\u001B[1;32m    517\u001B[0m     \u001B[38;5;66;03m# [batch,100,freq_numbers]  omega_z1.unsqueeze(1) is [batch,1,freq_numbers]\u001B[39;00m\n\u001B[0;32m--> 518\u001B[0m     z1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msin(\u001B[43momega_value_var1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata_t\u001B[49m)  \u001B[38;5;66;03m# Broadcasting is done here\u001B[39;00m\n\u001B[1;32m    520\u001B[0m     z1_left_matirx[:, :, \u001B[38;5;241m1\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnon_zero_freq_num\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m z1\n\u001B[1;32m    521\u001B[0m     z2 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msin(omega_value_var2 \u001B[38;5;241m*\u001B[39mdata_t)  \u001B[38;5;66;03m# Broadcasting is done here\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (256) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# return test' results\n",
    "expr2.do_expr(                          results_save_path=results_path,\n",
    "                                        folder_num=97,\n",
    "                                        train_config=expr2.config,\n",
    "                                        model_type=\"inference_net\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:11:51.950381Z",
     "start_time": "2023-10-17T11:11:50.765038Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## here is a plot function to output a figure\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss(path, loss_train, x_log=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Plot loss.\n",
    "    Args:\n",
    "        path (str): path.\n",
    "        loss_train (list): list of training loss.\n",
    "        x_log (bool): whether to use log scale for x-axis.\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    y2 = np.asarray(loss_train)\n",
    "    plt.plot(y2, 'k-', label='Train')\n",
    "    plt.xlabel('epoch', fontsize=18)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    plt.yscale('log')\n",
    "    if x_log == False:\n",
    "        fntmp = os.path.join(path, 'loss.png')\n",
    "\n",
    "    else:\n",
    "        plt.xscale('log')\n",
    "        fntmp = os.path.join(path, 'loss_log.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fntmp,dpi=300)\n",
    "\n",
    "    plt.close()\n",
    "def plot_model_output(path, args, output, epoch):\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    plt.plot(args.training_input.detach().cpu().numpy(),\n",
    "             args.training_target.detach().cpu().numpy(), 'b*', label='True')\n",
    "    plt.plot(args.test_input.detach().cpu().numpy(),\n",
    "             output.detach().cpu().numpy(), 'r-', label='Test')\n",
    "\n",
    "    ax.tick_params(labelsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    fntmp = os.path.join(path, 'output', str(epoch)+'.png')\n",
    "\n",
    "    plt.savefig(fntmp, dpi=300)\n",
    "\n",
    "\n",
    "    plt.close()\n",
    "def my_fft(data, freq_len=40, isnorm=1):\n",
    "\n",
    "    \"\"\"\n",
    "    This function performs FFT on the given data.\n",
    "\n",
    "    Args:\n",
    "    data (numpy.ndarray): The input data.\n",
    "    freq_len (int): The length of the frequency.\n",
    "    isnorm (int): The normalization factor.\n",
    "\n",
    "    Returns:\n",
    "    return_fft (numpy.ndarray): The FFT output array.\n",
    "    \"\"\"\n",
    "\n",
    "    # second_diff_input = np.mean(np.diff(np.diff(np.squeeze(x_input))))\n",
    "    # if abs(second_diff_input) < 1e-10:\n",
    "    datat = np.squeeze(data)\n",
    "    datat_fft = np.fft.fft(datat)\n",
    "    ind2 = range(freq_len)\n",
    "    fft_coe = datat_fft[ind2]\n",
    "    if isnorm == 1:\n",
    "        return_fft = np.absolute(fft_coe)\n",
    "    else:\n",
    "        return_fft = fft_coe\n",
    "\n",
    "    return return_fft\n",
    "def SelectPeakIndex(FFT_Data, endpoint=True):\n",
    "\n",
    "    \"\"\"\n",
    "    This function selects the peak index from FFT data.\n",
    "\n",
    "    Args:\n",
    "    FFT_Data (numpy.ndarray): The FFT data array.\n",
    "    endpoint (bool): Whether to include endpoints or not. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    sel_ind (numpy.ndarray): Selected index array with peaks.\n",
    "    \"\"\"\n",
    "\n",
    "    D1 = FFT_Data[1:-1]-FFT_Data[0:-2]\n",
    "    D2 = FFT_Data[1:-1]-FFT_Data[2:]\n",
    "    D3 = np.logical_and(D1 > 0, D2 > 0)\n",
    "    tmp = np.where(D3 == True)\n",
    "    sel_ind = tmp[0]+1\n",
    "    if endpoint: #\n",
    "        if FFT_Data[0]-FFT_Data[1] > 0:\n",
    "            sel_ind = np.concatenate([[0], sel_ind])\n",
    "        if FFT_Data[-1]-FFT_Data[-2] > 0:\n",
    "            Last_ind = len(FFT_Data)-1\n",
    "            sel_ind = np.concatenate([sel_ind, [Last_ind]])\n",
    "    return sel_ind\n",
    "def plot_freq_distr(args):\n",
    "    \"\"\"\n",
    "    Plot frequency distribution and the heatmap of the given training target and output.\n",
    "\n",
    "    Args:\n",
    "    args: A dictionary containing training target and output.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    y_fft = my_fft(args.training_target.detach().cpu().numpy()) / \\\n",
    "        args.training_size\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    plt.semilogy(y_fft+1e-5, label='Target')\n",
    "    idx = SelectPeakIndex(y_fft, endpoint=False)\n",
    "    plt.semilogy(idx, y_fft[idx]+1e-5, 'o')\n",
    "    y_fft_pred = my_fft(args.training_output[-1])/args.training_size\n",
    "    plt.semilogy(y_fft_pred+1e-5, label='Model output')\n",
    "    plt.semilogy(idx, y_fft_pred[idx]+1e-5, 'o')\n",
    "    plt.legend(fontsize=22)\n",
    "    plt.xlabel('freq idx', fontsize=22)\n",
    "    plt.ylabel('freq', fontsize=22)\n",
    "    plt.gca().tick_params(axis='y', labelsize=22)\n",
    "    plt.gca().tick_params(axis='x', labelsize=22)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(args.path, 'fft.png'), dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    y_pred_epoch = np.squeeze(args.training_output)\n",
    "    idx1 = idx[:3]\n",
    "    abs_err = np.zeros([len(idx1), len(args.training_output)])\n",
    "    y_fft = my_fft(args.training_target)\n",
    "    tmp1 = y_fft[idx1]\n",
    "    print(abs_err.shape)\n",
    "    for i in range(len(y_pred_epoch)):\n",
    "        tmp2 = my_fft(y_pred_epoch[i])[idx1]\n",
    "        abs_err[:, i] = np.abs(tmp1 - tmp2)/(1e-5 + tmp1)\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = plt.gca()\n",
    "    plt.pcolor(abs_err, cmap='RdBu', vmin=0.1, vmax=1, linewidths=0.4)\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "    plt.xlabel('Epoch', fontsize=22)\n",
    "\n",
    "    # Set the y-axis ticks and labels to 1, 2, 3, and rotate the labels\n",
    "    plt.yticks([0.5, 1.5, 2.5], [1, 2, 3], rotation=0, fontsize=22)\n",
    "\n",
    "    # Set the y-axis tick parameters to hide the tick marks and set the tick label size\n",
    "    plt.gca().yaxis.set_tick_params(size=0)\n",
    "    plt.gca().tick_params(axis='y', labelsize=22)\n",
    "    plt.gca().tick_params(axis='x', labelsize=22)\n",
    "\n",
    "\n",
    "    plt.title('Absolute Error', fontsize=22)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(args.path, 'hot.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "def plot_target_pred_result(target,pred):\n",
    "    \"\"\"\n",
    "    Plot the target.\n",
    "\n",
    "    Args:\n",
    "        target_tensor_tensor (torch.Tensor): The target tensor.\n",
    "        pred_tensor (torch.Tensor): The prediction tensor.\n",
    "\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    plt.plot(target.detach().cpu().numpy(),\n",
    "             target.cpu().numpy(), 'b*', label='True')\n",
    "    plt.plot(target.detach().cpu().numpy(),\n",
    "             pred.cpu().numpy(), 'r-', label='Test')\n",
    "\n",
    "    ax.tick_params(labelsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.show()\n",
    "    print(\"The target function:\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T06:00:35.014480Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# read the .pth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis_pth=\"/Users/liangaoming/Documents/Ai_station/neural_find_sol/wgan_2nd/expr2/expr2_results/expr2_97_data/train_process/inference_net/analysis_files/tensor_0.pth\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "import torch\n",
    "index= torch.randint(low=0,high=100, size=(20,))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T16:09:04.424356Z",
     "start_time": "2023-10-16T16:09:04.359409Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled indices: tensor([2, 2, 0, 3, 2, 2, 3, 5, 0, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设有10个位置，其中索引 2 的权重最高\n",
    "weights = torch.tensor([0.05, 0.05, 0.4, 0.05, 0.05, 0.1, 0.1, 0.1, 0.05, 0.05])\n",
    "\n",
    "# 采样 10 个索引，允许重复\n",
    "sampled_indices = torch.multinomial(weights, 10, replacement=True)\n",
    "\n",
    "print(\"Sampled indices:\", sampled_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T16:16:14.977168Z",
     "start_time": "2023-10-16T16:16:14.893471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "Result tensor shape: torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 初始化一个三维张量，维度为 [256, 100, 2]\n",
    "tensor = torch.rand([256, 100, 2])\n",
    "\n",
    "# 初始化一个用于存储结果的列表\n",
    "result_list = []\n",
    "\n",
    "# 在第二个维度（大小为100）上应用多项式随机抽样\n",
    "for i in range(tensor.shape[0]):\n",
    "    # 对每一个 [100, 2] 的子张量应用 torch.multinomial\n",
    "    sampled_indices = torch.multinomial(tensor[i,:,0], 10, replacement=True)  # 假设我们抽样10个点\n",
    "    print(sampled_indices.shape)\n",
    "    result_list.append(sampled_indices)\n",
    "\n",
    "# 将结果转化为张量\n",
    "result_tensor = torch.stack(result_list, dim=0)\n",
    "\n",
    "print(\"Result tensor shape:\", result_tensor.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T16:22:01.570542Z",
     "start_time": "2023-10-16T16:22:01.513Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[67, 42, 67,  ...,  0, 53, 34],\n        [91,  2, 55,  ..., 93, 32, 24],\n        [30,  5, 16,  ...,  3, 31,  7],\n        ...,\n        [79, 52, 53,  ..., 74, 23, 82],\n        [50, 43, 77,  ..., 97, 76, 91],\n        [20, 41, 56,  ..., 15, 80, 51]])"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T16:21:17.171826Z",
     "start_time": "2023-10-16T16:21:17.115745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (3,) and arg 1 with shape (36,).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[330], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m labels \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClass 0\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClass 1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClass 2\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     17\u001B[0m y_pos \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;28mlen\u001B[39m(labels))\n\u001B[0;32m---> 19\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcounts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malign\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcenter\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m plt\u001B[38;5;241m.\u001B[39mxticks(y_pos, labels)\n\u001B[1;32m     21\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClasses\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/matplotlib/pyplot.py:2439\u001B[0m, in \u001B[0;36mbar\u001B[0;34m(x, height, width, bottom, align, data, **kwargs)\u001B[0m\n\u001B[1;32m   2435\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mbar)\n\u001B[1;32m   2436\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbar\u001B[39m(\n\u001B[1;32m   2437\u001B[0m         x, height, width\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m, bottom\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, align\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcenter\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   2438\u001B[0m         data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m-> 2439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbar\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2440\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbottom\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbottom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malign\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malign\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2441\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/matplotlib/__init__.py:1446\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[0;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1443\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m   1444\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1446\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1448\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1449\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[1;32m   1450\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/matplotlib/axes/_axes.py:2409\u001B[0m, in \u001B[0;36mAxes.bar\u001B[0;34m(self, x, height, width, bottom, align, **kwargs)\u001B[0m\n\u001B[1;32m   2406\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m yerr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2407\u001B[0m         yerr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_dx(yerr, y0, y, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_yunits)\n\u001B[0;32m-> 2409\u001B[0m x, height, width, y, linewidth, hatch \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2410\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Make args iterable too.\u001B[39;49;00m\n\u001B[1;32m   2411\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43matleast_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlinewidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2413\u001B[0m \u001B[38;5;66;03m# Now that units have been converted, set the tick locations.\u001B[39;00m\n\u001B[1;32m   2414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m orientation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvertical\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mbroadcast_arrays\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/stride_tricks.py:540\u001B[0m, in \u001B[0;36mbroadcast_arrays\u001B[0;34m(subok, *args)\u001B[0m\n\u001B[1;32m    533\u001B[0m \u001B[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001B[39;00m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001B[39;00m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001B[39;00m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;66;03m#                  order='C').itviews\u001B[39;00m\n\u001B[1;32m    538\u001B[0m args \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39marray(_m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, subok\u001B[38;5;241m=\u001B[39msubok) \u001B[38;5;28;01mfor\u001B[39;00m _m \u001B[38;5;129;01min\u001B[39;00m args]\n\u001B[0;32m--> 540\u001B[0m shape \u001B[38;5;241m=\u001B[39m \u001B[43m_broadcast_shape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(array\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m shape \u001B[38;5;28;01mfor\u001B[39;00m array \u001B[38;5;129;01min\u001B[39;00m args):\n\u001B[1;32m    543\u001B[0m     \u001B[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001B[39;00m\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m args\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/stride_tricks.py:422\u001B[0m, in \u001B[0;36m_broadcast_shape\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001B[39;00m\n\u001B[1;32m    418\u001B[0m \u001B[38;5;124;03msupplied arrays against each other.\u001B[39;00m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001B[39;00m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;66;03m# consistently\u001B[39;00m\n\u001B[0;32m--> 422\u001B[0m b \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001B[39;00m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pos \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m32\u001B[39m, \u001B[38;5;28mlen\u001B[39m(args), \u001B[38;5;241m31\u001B[39m):\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001B[39;00m\n\u001B[1;32m    426\u001B[0m     \u001B[38;5;66;03m# objects (it treats them as scalars)\u001B[39;00m\n\u001B[1;32m    427\u001B[0m     \u001B[38;5;66;03m# use broadcasting to avoid allocating the full array\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (3,) and arg 1 with shape (36,)."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 权重和样本数\n",
    "weights = torch.tensor([0.2, 0.3, 0.5])\n",
    "n_samples = 1000\n",
    "\n",
    "# 使用 torch.multinomial 进行多项式抽样\n",
    "samples = torch.multinomial(weights, n_samples, replacement=True)\n",
    "samples=torch.tensor([ 1,  6,  0,  7,  4,  3,  8, 22,  2, 23, 14, 35])\n",
    "# 计数每个类别的样本数\n",
    "counts = torch.bincount(samples)\n",
    "\n",
    "# 可视化\n",
    "labels = ['Class 0', 'Class 1', 'Class 2']\n",
    "y_pos = np.arange(len(labels))\n",
    "\n",
    "plt.bar(y_pos, counts, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, labels)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Multinomial Distribution Sampling')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T08:04:05.166231Z",
     "start_time": "2023-10-17T08:04:05.021771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n        [2.0000, 2.0000, 2.0000, 3.2300]])"
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.arange(1, 11).reshape((2, 5))\n",
    "src\n",
    "index = torch.tensor([[0, 1, 2, 0]])\n",
    "torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
    "index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
    "torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
    "\n",
    "torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
    "           1.23, reduce='multiply')\n",
    "torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
    "           1.23, reduce='add')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T09:50:36.681532Z",
     "start_time": "2023-10-17T09:50:36.620449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:00:42.132119Z",
     "start_time": "2023-10-17T10:00:42.126255Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def scatter_tensor(sample_index, freq):\n",
    "    # 创建目标张量\n",
    "    target_shape = (sample_index.size(0), 1, sample_index.size(1))\n",
    "    target = torch.zeros(target_shape, dtype=torch.float32)\n",
    "\n",
    "    # 创建索引张量\n",
    "    index = sample_index.unsqueeze(1)\n",
    "\n",
    "    # 将源张量转换为与目标张量相同的数据类型\n",
    "    source = freq.to(target.dtype)\n",
    "\n",
    "    # 使用 scatter 函数将源张量的值散布到目标张量的指定位置\n",
    "    target.scatter_(2, index, source)\n",
    "\n",
    "    return target\n",
    "\n",
    "# 示例用法\n",
    "sample_index = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]] * 256)\n",
    "freq = torch.rand(256, 50)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:15:32.510819Z",
     "start_time": "2023-10-17T10:15:32.453639Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [],
   "source": [
    "a=freq[sample_index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:15:32.892227Z",
     "start_time": "2023-10-17T10:15:32.845732Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([256, 12, 50])"
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:15:33.466549Z",
     "start_time": "2023-10-17T10:15:33.409301Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([256, 50])"
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:15:34.518754Z",
     "start_time": "2023-10-17T10:15:34.468757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 示例用法\n",
    "target = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]] * 256)\n",
    "index = torch.tensor([[1,9]])\n",
    "\n",
    "result = torch.gather(target, 1, index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:51:48.842619Z",
     "start_time": "2023-10-17T10:51:48.708049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([256, 12])"
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:51:49.120716Z",
     "start_time": "2023-10-17T10:51:49.073082Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 2])"
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:51:49.845417Z",
     "start_time": "2023-10-17T10:51:49.783788Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2, 10]])"
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:51:50.596498Z",
     "start_time": "2023-10-17T10:51:50.547482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0.]], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 目标张量\n",
    "target = torch.tensor([[1, 2, 3, 4],\n",
    "                       [5, 6, 7, 8],\n",
    "                       [9, 10, 11, 12]], dtype=torch.float, requires_grad=True)\n",
    "\n",
    "# 索引张量\n",
    "index = torch.tensor([[0, 2],\n",
    "                      [1, 3],\n",
    "                      [2, 0]])\n",
    "\n",
    "# 使用 torch.gather() 函数进行索引选择\n",
    "result = torch.gather(target, 1, index)\n",
    "\n",
    "# 计算损失函数\n",
    "loss = result.sum()\n",
    "\n",
    "# 反向传播\n",
    "loss.backward()\n",
    "\n",
    "# 输出梯度\n",
    "print(target.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:26:21.029940Z",
     "start_time": "2023-10-17T10:26:20.960286Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "outputs": [],
   "source": [
    "a=torch.tensor([[6,1],[1,2],[1,4]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:00:37.097794Z",
     "start_time": "2023-10-17T11:00:37.040024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 2])"
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:00:37.598902Z",
     "start_time": "2023-10-17T11:00:37.552053Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.1468e-01,  7.3732e-01,  7.0448e-01],\n",
      "        [-9.1085e-01, -6.7443e-01,  1.7177e-01],\n",
      "        [ 3.9727e-01,  9.5686e-02,  3.7899e-01],\n",
      "        [ 1.1999e+00,  2.1863e+00, -1.3967e+00],\n",
      "        [ 1.0571e+00, -8.2791e-01,  2.8899e-01],\n",
      "        [ 1.9661e+00, -1.4876e+00, -6.9514e-01],\n",
      "        [ 6.6570e-02,  1.4638e+00, -6.9084e-02],\n",
      "        [ 9.9553e-01,  9.8115e-01, -6.8874e-01],\n",
      "        [-1.2459e+00,  8.6411e-01,  1.2225e+00],\n",
      "        [-3.3574e-01, -2.7598e-01, -1.0885e-01],\n",
      "        [ 4.1174e-01, -2.0071e-01,  6.4772e-01],\n",
      "        [-1.5477e+00, -6.3011e-01,  3.7211e-01],\n",
      "        [ 2.7565e-01, -7.5997e-01,  2.7076e-01],\n",
      "        [ 1.5174e-01,  6.8031e-01,  6.2748e-01],\n",
      "        [-2.3882e-01,  9.9670e-01,  4.1753e-01],\n",
      "        [-1.7769e-01, -4.9185e-01, -3.2620e-03],\n",
      "        [-2.4321e-01, -1.8450e-01,  3.6088e-01],\n",
      "        [-3.1508e-01,  1.1992e+00, -6.9334e-02],\n",
      "        [-2.3590e-01,  1.7164e+00, -2.0559e+00],\n",
      "        [-4.9104e-01,  1.6472e+00, -1.4411e+00],\n",
      "        [-1.2523e+00, -2.0957e-01, -7.1787e-01],\n",
      "        [-5.1431e-01, -4.2370e-01, -1.6224e+00],\n",
      "        [ 8.6480e-01,  8.5112e-02, -9.5074e-01],\n",
      "        [ 1.6698e+00, -7.6869e-01, -1.1851e+00],\n",
      "        [-2.1675e-01, -2.7584e-01, -1.3025e+00],\n",
      "        [-1.1966e-01,  1.7205e+00, -9.9026e-01],\n",
      "        [ 6.4010e-01, -1.3083e+00,  1.1152e-01],\n",
      "        [-1.0270e+00, -7.0274e-01,  2.4223e-01],\n",
      "        [-2.2171e-01,  1.7976e+00, -1.7386e-01],\n",
      "        [ 1.0534e+00, -8.0135e-01,  5.3536e-01],\n",
      "        [ 1.2986e+00, -1.7732e+00,  4.2706e-01],\n",
      "        [ 3.8430e-01,  1.3008e-01,  2.3791e+00],\n",
      "        [-1.4165e+00,  1.4157e+00, -1.3607e+00],\n",
      "        [-7.5935e-01,  2.0845e+00,  8.5907e-01],\n",
      "        [-5.3557e-01, -1.8127e+00,  1.4933e-01],\n",
      "        [ 8.7607e-01,  2.2854e+00, -1.6376e+00],\n",
      "        [ 2.3214e-01,  5.1168e-01, -7.9589e-01],\n",
      "        [ 5.3917e-01,  3.2465e-01, -2.2327e-01],\n",
      "        [ 3.2444e-01, -6.1160e-01, -2.5643e-01],\n",
      "        [-1.7581e+00, -1.1834e-01,  5.5763e-01],\n",
      "        [-7.5002e-01, -7.3238e-01, -7.4815e-01],\n",
      "        [ 1.3411e+00, -2.0476e-01, -5.5643e-01],\n",
      "        [ 9.5853e-01,  7.9387e-01, -1.2995e+00],\n",
      "        [ 2.2477e+00, -7.1266e-01, -8.2068e-03],\n",
      "        [-1.2981e+00, -5.6787e-01, -4.1701e-02],\n",
      "        [ 3.4539e-01, -9.9171e-02,  7.1814e-01],\n",
      "        [-8.7266e-01,  1.2509e+00, -1.8173e+00],\n",
      "        [-3.8834e-01,  1.6282e+00,  2.6577e-02],\n",
      "        [ 7.4508e-01,  1.2001e-01,  7.4508e-01],\n",
      "        [-9.1613e-01,  1.5670e-01,  3.4061e-01],\n",
      "        [-2.0225e+00, -2.5234e-01, -1.2386e+00],\n",
      "        [-4.9923e-02,  6.1340e-01,  1.5874e+00],\n",
      "        [-2.3005e+00,  9.4947e-02, -7.5910e-01],\n",
      "        [-5.7145e-01,  2.6518e-01,  1.0591e+00],\n",
      "        [-1.2295e-01,  2.4865e-01,  2.7874e-01],\n",
      "        [ 4.3850e-01, -3.8066e-01, -8.3944e-01],\n",
      "        [ 1.1877e+00, -6.4557e-02,  1.1877e+00],\n",
      "        [ 4.2959e-01,  4.1673e-01,  4.1160e-01],\n",
      "        [ 9.7308e-01, -1.8223e+00,  1.2920e+00],\n",
      "        [-5.8027e-02, -1.1341e+00, -6.6378e-01],\n",
      "        [ 1.8971e-02, -1.0143e+00, -7.5402e-02],\n",
      "        [-3.0916e-01,  7.0334e-01, -6.2011e-01],\n",
      "        [-1.2053e+00,  8.8599e-01,  3.5799e-01],\n",
      "        [ 8.7179e-01,  1.1707e-01,  5.3234e-01],\n",
      "        [ 8.8004e-02,  9.2799e-01,  2.6532e-01],\n",
      "        [ 1.1067e+00,  8.3031e-01,  4.6211e-01],\n",
      "        [ 1.3260e-01,  6.0704e-01, -2.7268e+00],\n",
      "        [ 7.5760e-01, -8.8684e-03,  4.9126e-01],\n",
      "        [-5.3545e-01, -1.2346e+00, -9.9657e-01],\n",
      "        [ 1.3861e+00, -2.5649e-01, -2.2163e+00],\n",
      "        [ 2.9183e-01,  6.6156e-01,  3.1824e-01],\n",
      "        [-5.3704e-01,  4.9369e-01,  9.2666e-02],\n",
      "        [ 3.2048e-01, -2.2696e-01, -7.0243e-01],\n",
      "        [ 6.8455e-01,  1.6947e-01,  4.5166e-01],\n",
      "        [ 1.9356e-01, -1.3399e+00, -4.3002e-01],\n",
      "        [ 2.0582e-01, -2.1613e-01, -4.2200e-01],\n",
      "        [ 6.0189e-01,  4.1314e-01, -5.7845e-01],\n",
      "        [-9.9602e-01,  1.4060e+00, -1.0281e+00],\n",
      "        [ 2.9579e-01,  6.8913e-01,  3.5616e-01],\n",
      "        [-1.4677e+00,  7.7512e-01,  1.0126e+00],\n",
      "        [-1.5993e+00, -3.6417e-01,  5.3540e-01],\n",
      "        [ 2.8411e-02,  2.1586e-01,  1.3061e+00],\n",
      "        [ 3.2538e-01,  8.7622e-01, -3.6086e-01],\n",
      "        [ 1.6738e-01,  1.7887e+00, -8.8286e-01],\n",
      "        [-1.5267e+00,  9.9724e-02,  6.3151e-01],\n",
      "        [ 1.3611e+00, -1.0262e+00, -1.2438e-01],\n",
      "        [ 2.1442e-01,  2.1027e-01,  2.4288e+00],\n",
      "        [ 7.0759e-02, -3.4676e-01,  1.1434e+00],\n",
      "        [-3.2550e-01,  9.4471e-01,  3.6738e-01],\n",
      "        [-4.3570e-01, -7.4600e-03,  1.0657e+00],\n",
      "        [-4.9222e-02,  1.6753e-01, -6.2839e-01],\n",
      "        [-5.5428e-01,  2.5046e-01,  1.1045e+00],\n",
      "        [-2.3922e-02, -1.1190e+00,  2.2175e-01],\n",
      "        [-1.5193e-01, -8.4174e-01,  2.1561e-01],\n",
      "        [ 8.4618e-01, -6.6969e-01, -1.1042e+00],\n",
      "        [ 1.1293e-01,  5.4866e-01, -4.3860e-01],\n",
      "        [ 1.6274e+00,  3.4411e-01,  9.5762e-01],\n",
      "        [-7.9288e-01, -8.9483e-01,  8.3697e-01],\n",
      "        [ 2.2045e+00, -1.9360e-01, -3.1517e-01],\n",
      "        [-8.0618e-01,  3.7230e-02,  7.8470e-01],\n",
      "        [-7.2537e-01, -1.1057e+00,  6.1834e-01],\n",
      "        [ 1.6258e-01,  6.7533e-01,  6.7533e-01],\n",
      "        [ 7.5116e-02,  3.2571e-01, -1.3226e+00],\n",
      "        [-1.1348e+00,  2.0030e-01, -6.3654e-01],\n",
      "        [ 1.3304e+00,  1.0270e+00, -4.1972e-01],\n",
      "        [ 1.2984e+00,  1.1805e+00,  1.0573e+00],\n",
      "        [ 4.7952e-01, -3.9449e-01,  6.0791e-02],\n",
      "        [-1.5697e-01, -1.0706e+00, -7.3289e-01],\n",
      "        [-2.5512e+00, -5.5711e-01,  1.9118e-01],\n",
      "        [ 1.2847e+00, -1.0455e+00,  1.5387e-01],\n",
      "        [-4.4536e-01, -6.0418e-01, -9.3979e-01],\n",
      "        [-3.5954e-01, -1.5660e+00, -1.5431e+00],\n",
      "        [ 3.5687e-01, -1.5471e+00, -5.5235e-01],\n",
      "        [ 6.8475e-01, -9.8758e-01,  9.6882e-01],\n",
      "        [ 2.4207e+00,  7.9114e-01, -3.7806e-01],\n",
      "        [ 1.3308e+00,  1.4019e+00, -1.4068e+00],\n",
      "        [-4.4235e-01,  3.4077e-01,  1.6646e-01],\n",
      "        [ 1.7739e+00,  9.7113e-01,  4.6577e-01],\n",
      "        [-1.1451e+00, -1.0252e+00, -8.2884e-02],\n",
      "        [ 8.6843e-01,  1.0981e+00, -1.3492e+00],\n",
      "        [-1.3826e+00,  1.8071e-01, -1.4381e-01],\n",
      "        [ 7.9797e-01,  1.1718e+00,  7.7598e-01],\n",
      "        [-2.1712e+00, -5.3350e-01, -6.2084e-01],\n",
      "        [ 9.5212e-01,  1.5384e+00, -6.9691e-01],\n",
      "        [-2.5474e-01, -8.7350e-01, -2.0918e-01],\n",
      "        [-1.1609e-01, -3.7131e-01, -3.7356e-01],\n",
      "        [-1.3554e+00, -5.6344e-01, -4.4552e-01],\n",
      "        [-4.0812e-01, -5.9234e-02, -2.1437e+00],\n",
      "        [-7.4713e-01,  1.5537e+00, -1.1385e-01],\n",
      "        [-1.5334e-01,  3.6848e-01, -3.4871e-01],\n",
      "        [-2.0376e-01, -1.6109e+00, -2.7170e-01],\n",
      "        [-2.0461e+00, -1.5468e-01, -1.3354e+00],\n",
      "        [ 6.4760e-01, -1.9680e+00,  3.8236e+00],\n",
      "        [ 9.8344e-01, -7.1443e-02, -2.8851e-01],\n",
      "        [-3.3751e-01,  3.9043e-01,  7.3998e-01],\n",
      "        [ 1.9946e-01, -1.7158e+00,  5.9656e-01],\n",
      "        [-9.7283e-01,  9.4473e-02, -3.9123e-01],\n",
      "        [-1.3968e+00, -1.3968e+00, -1.4091e+00],\n",
      "        [-1.4089e+00, -7.9898e-01,  1.1534e+00],\n",
      "        [-3.9346e-02,  1.5668e+00, -1.8603e-02],\n",
      "        [ 1.7043e+00,  1.9605e+00, -2.8083e-01],\n",
      "        [-7.8290e-01, -7.8290e-01,  2.4876e+00],\n",
      "        [-7.9311e-01, -5.0688e-01, -2.5740e+00],\n",
      "        [ 7.2637e-01, -1.2758e-01,  1.0250e+00],\n",
      "        [-6.4649e-01, -1.5689e+00, -1.5689e+00],\n",
      "        [-8.2379e-01,  1.9483e+00, -9.1286e-01],\n",
      "        [ 2.8133e-01,  1.3098e+00,  1.3032e+00],\n",
      "        [-4.4944e-01, -6.7573e-01, -9.5529e-01],\n",
      "        [ 8.0741e-02,  8.0741e-02, -7.2426e-02],\n",
      "        [-6.6631e-02, -2.8476e-01, -3.0653e-01],\n",
      "        [ 1.8358e+00,  2.2660e-01,  4.0213e-02],\n",
      "        [ 2.3773e-01, -2.7669e-02,  2.0305e+00],\n",
      "        [-1.9147e+00,  2.8406e-01, -8.1041e-01],\n",
      "        [-4.9454e-01,  3.3986e-01,  8.7837e-01],\n",
      "        [-6.7839e-01, -1.1185e+00,  1.9856e+00],\n",
      "        [ 1.0211e+00,  2.1080e-01,  1.2315e+00],\n",
      "        [ 1.5712e+00, -5.3050e-01,  1.0105e-01],\n",
      "        [-3.0027e-01,  3.0410e-01, -8.5440e-01],\n",
      "        [ 1.2671e-01, -1.3443e+00,  1.3582e-01],\n",
      "        [ 9.8628e-01,  4.3956e-02,  5.7501e-02],\n",
      "        [-7.8472e-01,  5.1805e-01,  3.8154e-01],\n",
      "        [-1.4332e+00,  8.5479e-01, -2.1037e-01],\n",
      "        [ 7.6786e-01,  1.0607e-01, -1.4495e-01],\n",
      "        [-1.1234e+00,  4.5179e-01, -9.8589e-01],\n",
      "        [-1.3272e+00, -9.1168e-01,  5.1554e-01],\n",
      "        [-2.4630e-01, -6.4492e-01, -5.8679e-01],\n",
      "        [-3.3634e-01,  5.9535e-01,  4.4169e-02],\n",
      "        [-2.0737e-01,  9.5259e-01,  6.4059e-01],\n",
      "        [-3.6118e-01, -4.7244e-01,  5.5743e-01],\n",
      "        [-4.4233e-01, -1.1735e+00,  8.5802e-01],\n",
      "        [ 1.6340e+00, -1.7501e+00,  1.0344e+00],\n",
      "        [ 6.2153e-01,  2.3545e-01, -1.7065e+00],\n",
      "        [ 4.6616e-02,  1.0807e+00,  2.0199e+00],\n",
      "        [-5.4323e-01, -8.7691e-01,  9.3366e-01],\n",
      "        [ 3.8193e-01,  7.2357e-01, -1.4535e+00],\n",
      "        [-2.8007e-01, -4.5677e-02, -7.0825e-01],\n",
      "        [ 9.4605e-02,  6.8956e-01,  4.8059e-02],\n",
      "        [-9.6228e-01, -1.8756e-01,  4.8634e-01],\n",
      "        [-4.7005e-01,  1.1296e+00,  1.9419e-02],\n",
      "        [ 7.8879e-01,  1.0478e-01,  9.9074e-01],\n",
      "        [ 1.2522e+00, -5.0967e-01, -8.9478e-01],\n",
      "        [-9.4024e-01, -1.1110e+00,  5.8461e-01],\n",
      "        [ 9.0174e-01,  6.5496e-01,  1.4708e-01],\n",
      "        [ 1.1578e+00,  4.1616e-01,  1.6453e+00],\n",
      "        [-1.1068e+00,  4.8515e-01, -8.9990e-01],\n",
      "        [-1.0061e+00,  7.9117e-01, -4.3497e-01],\n",
      "        [ 4.7526e-01, -4.0757e-01,  3.1927e-01],\n",
      "        [-6.0843e-01, -1.0612e+00, -1.3720e-01],\n",
      "        [-1.8305e-01,  6.7663e-01, -9.5685e-01],\n",
      "        [-4.0509e-02, -6.1095e-01, -4.8928e-01],\n",
      "        [ 1.0801e+00, -1.6632e+00,  2.8446e-02],\n",
      "        [ 1.3861e-01, -4.0077e-02, -5.4986e-01],\n",
      "        [ 4.0825e-01, -1.8002e+00, -7.8644e-01],\n",
      "        [ 4.9083e-01, -4.5815e-01, -1.6898e-01],\n",
      "        [-5.2904e-01, -1.8307e+00, -7.1004e-01],\n",
      "        [ 3.6215e-01,  7.5072e-01,  6.7285e-01],\n",
      "        [-1.0589e-01, -9.4277e-01,  3.4022e-01],\n",
      "        [-5.6147e-01, -4.9334e-01, -2.2681e+00],\n",
      "        [ 3.5767e-01,  2.8836e+00,  1.1489e+00],\n",
      "        [-8.4750e-01,  4.2632e-01,  5.1225e-01],\n",
      "        [ 5.8539e-01,  1.2837e+00,  1.8282e+00],\n",
      "        [-2.0151e+00, -3.0426e-01,  4.2280e-01],\n",
      "        [-7.8872e-01, -9.8688e-01, -1.1590e+00],\n",
      "        [ 1.5725e-01,  4.7804e-01,  5.2216e-01],\n",
      "        [-9.2577e-01,  7.7377e-01,  9.8307e-01],\n",
      "        [-1.0631e+00, -1.1744e+00, -1.1324e+00],\n",
      "        [ 4.2537e-01,  2.4021e+00,  9.5732e-01],\n",
      "        [ 5.4973e-01, -8.6591e-02, -1.9641e-02],\n",
      "        [ 4.4408e-01,  1.6622e+00,  1.1174e+00],\n",
      "        [-2.2243e+00, -2.9407e-01, -1.2223e+00],\n",
      "        [ 2.2945e-01, -7.4737e-01, -6.1207e-01],\n",
      "        [-9.6987e-02,  4.1717e-01,  4.3707e-01],\n",
      "        [-8.2176e-01,  4.3047e-01, -5.6289e-02],\n",
      "        [-1.7852e+00, -7.3536e-02, -4.9772e-01],\n",
      "        [-1.4964e+00,  5.0510e-02,  1.9478e+00],\n",
      "        [-1.3734e+00, -4.8660e-02,  8.6368e-01],\n",
      "        [ 1.1318e+00, -1.3279e+00, -4.5681e-01],\n",
      "        [ 1.9647e+00, -8.9073e-01, -2.6266e-01],\n",
      "        [ 1.4448e+00,  1.0607e+00,  6.8334e-01],\n",
      "        [ 1.2565e+00, -6.2403e-01,  1.7540e+00],\n",
      "        [ 1.0130e-01, -9.2040e-01, -7.2653e-01],\n",
      "        [-1.1959e-01,  7.9296e-01, -2.9513e-01],\n",
      "        [-1.0680e+00,  2.2107e+00, -3.7256e-01],\n",
      "        [-3.3988e-01,  5.1362e-02,  2.0068e+00],\n",
      "        [-1.5426e+00, -6.0573e-01,  3.6275e-01],\n",
      "        [-3.9886e-02, -3.7354e-01, -1.8146e-01],\n",
      "        [-1.2898e+00,  5.4239e-02,  1.1938e+00],\n",
      "        [ 4.1845e-01,  1.2279e+00,  2.5594e-01],\n",
      "        [-4.0026e-01,  1.3865e+00, -2.2844e+00],\n",
      "        [ 1.3085e+00, -5.1583e-02, -1.1605e-01],\n",
      "        [ 1.0315e+00, -1.7853e-01,  9.8514e-01],\n",
      "        [-9.3913e-01,  2.3195e-01, -7.3321e-01],\n",
      "        [-2.4012e+00,  5.6446e-01,  3.1660e-01],\n",
      "        [-3.8500e-01, -7.4868e-01, -4.4256e-01],\n",
      "        [-8.8815e-01, -4.3593e-03, -9.0195e-01],\n",
      "        [-3.3398e-01, -1.9955e-01, -3.3398e-01],\n",
      "        [-1.0812e+00,  7.9904e-01, -1.9486e+00],\n",
      "        [ 1.0273e+00, -9.2281e-01,  8.5525e-01],\n",
      "        [ 4.8810e-01,  4.8059e-01, -7.6652e-01],\n",
      "        [ 3.7037e-01, -8.9619e-01,  1.7638e+00],\n",
      "        [ 4.4058e-01,  2.2296e-01,  4.7890e-01],\n",
      "        [-6.5291e-01, -2.3076e-01,  1.5444e+00],\n",
      "        [ 1.1038e+00,  1.7759e+00, -4.3193e-01],\n",
      "        [ 2.2253e+00,  7.1873e-01, -9.8618e-01],\n",
      "        [ 1.3939e+00, -1.6214e+00,  1.2160e+00],\n",
      "        [ 7.8512e-01,  1.0992e-01,  6.6767e-01],\n",
      "        [-1.3421e+00,  6.2552e-02, -1.1315e+00],\n",
      "        [ 1.9982e+00, -2.0630e+00,  1.8832e+00],\n",
      "        [ 1.0609e+00,  7.2503e-01, -6.7891e-01],\n",
      "        [ 8.5133e-02,  7.5948e-01, -4.7130e-01],\n",
      "        [-6.5513e-01, -1.8223e+00, -1.3235e+00],\n",
      "        [ 1.2212e+00,  1.0214e+00, -3.7729e-02],\n",
      "        [-7.8421e-03, -8.0514e-02, -2.0639e-01],\n",
      "        [ 8.5772e-02,  5.2301e-01,  2.1956e+00],\n",
      "        [-5.4385e-01,  3.4435e-01, -3.4237e-01],\n",
      "        [ 3.9644e-01, -3.4558e-01,  2.5857e-01]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "omega_value_var1 = torch.randn(256, 50)\n",
    "Sample_index = torch.randint(0, 50, (256, 3))\n",
    "\n",
    "result = torch.gather(omega_value_var1, 1, Sample_index)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:03:42.794505Z",
     "start_time": "2023-10-17T11:03:42.712790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([256, 3])"
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample_index.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:04:05.294116Z",
     "start_time": "2023-10-17T11:04:05.238139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
