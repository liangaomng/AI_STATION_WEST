{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:46:55.776603Z",
     "start_time": "2023-11-02T12:46:55.557482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import utlis_2nd.cusdom as custom\n",
    "import super_learn_task_expr2 as expr2\n",
    "import warnings\n",
    "\n",
    "read_abso_path=\"/Users/liangaoming/Documents/Ai_station/neural_find_sol/wgan_2nd/complex_center_dataset/combined_data.pt\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#data description\n",
    "Data_description=namedtuple(\"Data_description\",[\"t_steps\",\"vesting_s\",\"vari_numb\",\"sample_rate\",\"freq_numb\"])\n",
    "#temp info\n",
    "Soft_arg_temp = namedtuple(\"Soft_arg_temp\", [\"learnable\", \"value\"])\n",
    "Gumble_temp = namedtuple(\"Gumble_temp\", [\"learnable\", \"value\"])\n",
    "Sample_info = namedtuple(\"Sample_info\", [\"type\", \"sample_numb\"])\n",
    "#loss regularization\n",
    "Sinkhorn_loss_info = namedtuple(\"Sinkhorn_loss_info\", [\"loss_en\", \"p\",\"blur\"])\n",
    "Fourier_loss_info = namedtuple(\"Fourier_loss_info\", [\"loss_en\",\"labmbda_fourier\"])\n",
    "Lasso_loss_info = namedtuple(\"Lasso_loss_info\", [\"loss_en\", \"labmbda_lasso\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:46:56.364619Z",
     "start_time": "2023-11-02T12:46:56.308229Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data & read yaml\n",
      "shape: torch.Size([256, 100, 9])\n",
      "label for csv: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# split data & get the t_steps\n",
    "train_loader,valid_loader,test_loader,yaml_config =\\\n",
    "    custom.return_train_valid_test4loader(abso_path=read_abso_path)\n",
    "# look（shape）\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(\"shape:\", data.shape)\n",
    "    print(\"label for csv:\",target.shape)\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:46:57.588661Z",
     "start_time": "2023-11-02T12:46:56.528461Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "soft_arg_temp = Soft_arg_temp(\n",
    "                                learnable=yaml_config[\"Soft_argmax_info\"][0],\n",
    "                                value=yaml_config[\"Soft_argmax_info\"][1])\n",
    "gumble_temp = Gumble_temp(\n",
    "                            learnable=yaml_config[\"Gumble_info\"][0],\n",
    "                            value=yaml_config[\"Gumble_info\"][1])\n",
    "sample_info = Sample_info(\n",
    "                            type=yaml_config[\"Sample_info\"][0],\n",
    "                            sample_numb=yaml_config[\"Sample_info\"][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:46:57.642569Z",
     "start_time": "2023-11-02T12:46:57.590596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "results_path= \"/Users/liangaoming/Documents/Ai_station/neural_find_sol/wgan_2nd/expr2/expr2_results/expr2_\"\n",
    "expr2.config[\"train_nomin\"]= int((yaml_config['train_size_percent']*yaml_config['all_solus_numbers'])/yaml_config[\"batch_size\"])\n",
    "expr2.config[\"valid_nomin\"]= int((yaml_config['valid_size_percent']*yaml_config['all_solus_numbers'])/yaml_config[\"batch_size\"])\n",
    "expr2.config[\"test_nomin\"]= int((yaml_config['test_size_percent']*yaml_config['all_solus_numbers'])/yaml_config[\"batch_size\"])\n",
    "expr2.config[\"train_loader\"]= train_loader\n",
    "expr2.config[\"valid_loader\"]= valid_loader\n",
    "expr2.config[\"test_loader\"]= test_loader\n",
    "expr2.config[\"device\"] = \"cpu\"\n",
    "expr2.config[\"data_description\"]=yaml_config[\"data_description\"]\n",
    "expr2.config[\"hidden_act\"]= \"rational\"\n",
    "expr2.config[\"SI_lr\"]= 1e-5\n",
    "expr2.config[\"inference_output_act\"]=\"Identity\"\n",
    "expr2.config[\"vari_number\"]= yaml_config[\"vari_number\"]\n",
    "expr2.config[\"sample_vesting\"]=2 #2s\n",
    "#about temp\n",
    "expr2.config[\"soft_arg_info\"] = soft_arg_temp\n",
    "expr2.config[\"gumble_info\"] = gumble_temp\n",
    "expr2.config[\"sample_info\"] = sample_info\n",
    "#about regularization\n",
    "expr2.config[\"Sinkhorn_loss_info\"] = yaml_config[\"Sinkhorn_loss_info\"]\n",
    "expr2.config[\"Fourier_loss_info\"] = yaml_config[\"Fourier_loss_info\"]\n",
    "expr2.config[\"Lasso_loss_info\"] = yaml_config[\"Lasso_loss_info\"]\n",
    "#about train step and regularization\n",
    "expr2.config[\"Inference_num_epoch\"]=100\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:46:57.692182Z",
     "start_time": "2023-11-02T12:46:57.644349Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prior knowledge is {'basis_1': 'x**0', 'basis_2': 'sin', 'basis_3': 'cos'}\n",
      "output_dim 202\n",
      "output_act is Identity\n",
      "hi_inference_net\n",
      "test_only_inference\n",
      "start train_inference\n",
      "sink_info [False, 2, 0.05, 1]\n",
      "loss551.6992797851562_epoch0epoch_time2.005146026611328\n",
      "loss492.2245788574219_epoch1epoch_time1.9421517848968506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/__init__.py\", line 831, in <module>\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/__init__.py\", line 831, in <module>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/__init__.py\", line 831, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/functional.py\", line 8, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/functional.py\", line 8, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/functional.py\", line 8, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 20, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 2, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 18, in <module>\n",
      "    from .batchnorm import BatchNorm1d, BatchNorm2d, BatchNorm3d, SyncBatchNorm, \\\n",
      "    from .linear import Identity, Linear, Bilinear, LazyLinear\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py\", line 9, in <module>\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 7, in <module>\n",
      "    from .instancenorm import InstanceNorm1d, InstanceNorm2d, InstanceNorm3d, \\\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "    from .. import functional as F\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py\", line 18, in <module>\n",
      "    from .._jit_internal import boolean_dispatch, _overload, BroadcastingList1, BroadcastingList2, BroadcastingList3\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/_jit_internal.py\", line 39, in <module>\n",
      "    from ._functions import SyncBatchNorm as sync_batch_norm\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/nn/modules/_functions.py\", line 267, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "    class BackwardHookFunction(torch.autograd.Function):\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/autograd/function.py\", line 282, in __init__\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 975, in get_code\n",
      "    import torch.distributed.rpc\n",
      "  File \"/Users/liangaoming/anaconda3/lib/python3.10/site-packages/torch/distributed/rpc/__init__.py\", line 66, in <module>\n",
      "    def __init__(cls, name, bases, attrs):\n",
      "KeyboardInterrupt\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\n",
      "KeyboardInterrupt\n",
      "    from . import api, backend_registry, functions\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1439, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1411, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1548, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1591, in _fill_cache\n",
      "KeyboardInterrupt\n",
      "libc++abi: terminating with uncaught exception of type pybind11::error_already_set: KeyboardInterrupt: <EMPTY MESSAGE>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# return test' results\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m result,co_actor\u001B[38;5;241m=\u001B[39mexpr2\u001B[38;5;241m.\u001B[39mdo_expr(\n\u001B[1;32m      3\u001B[0m                                 results_save_path\u001B[38;5;241m=\u001B[39mresults_path,\n\u001B[1;32m      4\u001B[0m                                 folder_num\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m97\u001B[39m,\n\u001B[1;32m      5\u001B[0m                                 train_config\u001B[38;5;241m=\u001B[39mexpr2\u001B[38;5;241m.\u001B[39mconfig,\n\u001B[1;32m      6\u001B[0m                                 model_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minference_net\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Ai_station/neural_find_sol/wgan_2nd/expr2/super_learn_task_expr2.py:309\u001B[0m, in \u001B[0;36mdo_expr\u001B[0;34m(results_save_path, folder_num, train_config, model_type)\u001B[0m\n\u001B[1;32m    305\u001B[0m record_init(\n\u001B[1;32m    306\u001B[0m             folder_num\u001B[38;5;241m=\u001B[39mfolder_num,\n\u001B[1;32m    307\u001B[0m             expr_data_path_new\u001B[38;5;241m=\u001B[39mresults_save_path)\n\u001B[1;32m    308\u001B[0m save_config(train_config)\n\u001B[0;32m--> 309\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mexpr\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m            \u001B[49m\u001B[43mexpr_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtrain_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai_station/neural_find_sol/wgan_2nd/expr2/super_learn_task_expr2.py:270\u001B[0m, in \u001B[0;36mexpr\u001B[0;34m(expr_config, train_type)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (train_type\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minference_net\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    269\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhi_inference_net\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 270\u001B[0m     \u001B[43mtrain_inference_actor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mco_train_actor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mconfig_device\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpr_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdevice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    273\u001B[0m     test_dict\u001B[38;5;241m=\u001B[39mtest_inference_model(co_train_actor)\n\u001B[1;32m    275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m test_dict,\\\n\u001B[1;32m    276\u001B[0m            co_train_actor\n",
      "File \u001B[0;32m~/Documents/Ai_station/neural_find_sol/wgan_2nd/expr2/super_learn_task_expr2.py:181\u001B[0m, in \u001B[0;36mtrain_inference_actor\u001B[0;34m(co_train_actor, config_device)\u001B[0m\n\u001B[1;32m    179\u001B[0m uf\u001B[38;5;241m.\u001B[39mset_seed(config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    180\u001B[0m \u001B[38;5;66;03m#train the model\u001B[39;00m\n\u001B[0;32m--> 181\u001B[0m \u001B[43mco_train_actor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_inference_neural\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig_device\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43msinkhorn_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSinkhorn_loss_info\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai_station/neural_find_sol/utlis_2nd/co_train.py:60\u001B[0m, in \u001B[0;36mtrain_init.train_inference_neural\u001B[0;34m(self, process_name, device, save_2visualfig, sinkhorn_info)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mI_num_epoch):\n\u001B[1;32m     59\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 60\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, (batch_data, label) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader):\n\u001B[1;32m     61\u001B[0m         S_I_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     62\u001B[0m         \u001B[38;5;66;03m# get the condition_data and data_t and dict_str_solu\u001B[39;00m\n\u001B[1;32m     63\u001B[0m         \u001B[38;5;66;03m# real_data\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1315\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1316\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1317\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1318\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1319\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1279\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1281\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1282\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1283\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1284\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[1;32m   1108\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[1;32m   1109\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1117\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[1;32m   1118\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[1;32m   1119\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1120\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1121\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[1;32m   1122\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1123\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[1;32m   1124\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[1;32m   1125\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/multiprocessing/connection.py:424\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 424\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    928\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    933\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# return test' results\n",
    "result,co_actor=expr2.do_expr(\n",
    "                                results_save_path=results_path,\n",
    "                                folder_num=97,\n",
    "                                train_config=expr2.config,\n",
    "                                model_type=\"inference_net\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:47:06.671371Z",
     "start_time": "2023-11-02T12:46:58.245037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T05:55:44.184971Z",
     "start_time": "2023-10-27T05:55:44.175822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T05:55:44.812926Z",
     "start_time": "2023-10-27T05:55:44.787606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
